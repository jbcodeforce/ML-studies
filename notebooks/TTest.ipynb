{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# T-Tests and P-Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's say we're running an A/B test. We'll fabricate some data that randomly assigns order amounts from customers in sets A and B, with B being a little bit higher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "execution": {
     "iopub.execute_input": "2026-01-03T00:34:34.215469Z",
     "iopub.status.busy": "2026-01-03T00:34:34.215200Z",
     "iopub.status.idle": "2026-01-03T00:34:34.539328Z",
     "shell.execute_reply": "2026-01-03T00:34:34.538913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=np.float64(-15.024987252736254), pvalue=np.float64(9.53320201445273e-51), df=np.float64(19998.0))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "A = np.random.normal(25.0, 5.0, 10000)\n",
    "B = np.random.normal(26.0, 5.0, 10000)\n",
    "\n",
    "stats.ttest_ind(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The t-statistic is a measure of the difference between the two sets expressed in units of standard error. Put differently, it's the size of the difference relative to the variance in the data. A high t value means there's probably a real difference between the two sets; you have \"significance\". The P-value is a measure of the probability of an observation lying at extreme t-values; so a low p-value also implies \"significance.\" If you're looking for a \"statistically significant\" result, you want to see a very low p-value and a high t-statistic (well, a high absolute value of the t-statistic more precisely). In the real world, statisticians seem to put more weight on the p-value result.\n",
    "\n",
    "Let's change things up so both A and B are just random, generated under the same parameters. So there's no \"real\" difference between the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "execution": {
     "iopub.execute_input": "2026-01-03T00:34:34.556020Z",
     "iopub.status.busy": "2026-01-03T00:34:34.555893Z",
     "iopub.status.idle": "2026-01-03T00:34:34.558753Z",
     "shell.execute_reply": "2026-01-03T00:34:34.558355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=np.float64(-0.5171305934637209), pvalue=np.float64(0.6050707178052137), df=np.float64(19998.0))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.random.normal(25.0, 5.0, 10000)\n",
    "\n",
    "stats.ttest_ind(A, B)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, our t-statistic is much lower and our p-value is really high. This supports the null hypothesis - that there is no real difference in behavior between these two sets.\n",
    "\n",
    "Does the sample size make a difference? Let's do the same thing - where the null hypothesis is accurate - but with 10X as many samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "execution": {
     "iopub.execute_input": "2026-01-03T00:34:34.559905Z",
     "iopub.status.busy": "2026-01-03T00:34:34.559812Z",
     "iopub.status.idle": "2026-01-03T00:34:34.564961Z",
     "shell.execute_reply": "2026-01-03T00:34:34.564614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=np.float64(-0.14192692655361527), pvalue=np.float64(0.8871378682483085), df=np.float64(199998.0))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.normal(25.0, 5.0, 100000)\n",
    "B = np.random.normal(25.0, 5.0, 100000)\n",
    "\n",
    "stats.ttest_ind(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our p-value actually got a little lower, and the t-test a little larger, but still not enough to declare a real difference. So, you could have reached the right decision with just 10,000 samples instead of 100,000. Even a million samples doesn't help, so if we were to keep running this A/B test for years, you'd never acheive the result you're hoping for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "execution": {
     "iopub.execute_input": "2026-01-03T00:34:34.565952Z",
     "iopub.status.busy": "2026-01-03T00:34:34.565871Z",
     "iopub.status.idle": "2026-01-03T00:34:34.598430Z",
     "shell.execute_reply": "2026-01-03T00:34:34.598032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=np.float64(-0.8952362245435033), pvalue=np.float64(0.3706609319335492), df=np.float64(1999998.0))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.normal(25.0, 5.0, 1000000)\n",
    "B = np.random.normal(25.0, 5.0, 1000000)\n",
    "\n",
    "stats.ttest_ind(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If we compare the same set to itself, by definition we get a t-statistic of 0 and p-value of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "execution": {
     "iopub.execute_input": "2026-01-03T00:34:34.599489Z",
     "iopub.status.busy": "2026-01-03T00:34:34.599423Z",
     "iopub.status.idle": "2026-01-03T00:34:34.606769Z",
     "shell.execute_reply": "2026-01-03T00:34:34.606413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=np.float64(0.0), pvalue=np.float64(1.0), df=np.float64(1999998.0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(A, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The threshold of significance on p-value is really just a judgment call. As everything is a matter of probabilities, you can never definitively say that an experiment's results are \"significant\". But you can use the t-test and p-value as a measure of signficance, and look at trends in these metrics as the experiment runs to see if there might be something real happening between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Experiment with more different distributions for A and B, and see the effect it has on the t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
