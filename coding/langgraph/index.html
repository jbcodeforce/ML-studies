<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=https://jeromeboyer.net/ML-studies/coding/langgraph/ rel=canonical><link href=../langchain/ rel=prev><link href=../llama-index/ rel=next><link rel=icon href=../../assets/logo.drawio.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.18"><title>LangGraph - Machine Learning Studies - Jerome Boyer</title><link rel=stylesheet href=../../assets/stylesheets/main.7e37652d.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#langgraph class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Machine Learning Studies - Jerome Boyer" class="md-header__button md-logo" aria-label="Machine Learning Studies - Jerome Boyer" data-md-component=logo> <img src=../../assets/logo.drawio.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Machine Learning Studies - Jerome Boyer </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> LangGraph </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/jbcodeforce/ML-studies title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> About </a> </li> <li class=md-tabs__item> <a href=../../ml/ class=md-tabs__link> Machine Learning </a> </li> <li class=md-tabs__item> <a href=../../techno/airflow/ class=md-tabs__link> Techno </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> Coding </a> </li> <li class=md-tabs__item> <a href=../../solutions/ class=md-tabs__link> Solutions </a> </li> <li class=md-tabs__item> <a href=https://jbcodeforce.github.io class=md-tabs__link> Home </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Machine Learning Studies - Jerome Boyer" class="md-nav__button md-logo" aria-label="Machine Learning Studies - Jerome Boyer" data-md-component=logo> <img src=../../assets/logo.drawio.png alt=logo> </a> Machine Learning Studies - Jerome Boyer </label> <div class=md-nav__source> <a href=https://github.com/jbcodeforce/ML-studies title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <label class=md-nav__link for=__nav_1 id=__nav_1_label tabindex=0> <span class=md-ellipsis> About </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> About </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_2> <label class=md-nav__link for=__nav_1_2 id=__nav_1_2_label tabindex=0> <span class=md-ellipsis> Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_1_2> <span class="md-nav__icon md-icon"></span> Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../concepts/ class=md-nav__link> <span class=md-ellipsis> Core concepts </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/maths/ class=md-nav__link> <span class=md-ellipsis> Math summary </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/skill/ class=md-nav__link> <span class=md-ellipsis> Data scientist skill </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_3> <label class=md-nav__link for=__nav_1_3 id=__nav_1_3_label tabindex=0> <span class=md-ellipsis> Architecture </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_3_label aria-expanded=false> <label class=md-nav__title for=__nav_1_3> <span class="md-nav__icon md-icon"></span> Architecture </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../architecture/sol-design/ class=md-nav__link> <span class=md-ellipsis> Solution Design </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_4> <label class=md-nav__link for=__nav_1_4 id=__nav_1_4_label tabindex=0> <span class=md-ellipsis> Data management </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_1_4> <span class="md-nav__icon md-icon"></span> Data management </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../data/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../data/features/ class=md-nav__link> <span class=md-ellipsis> Feature Engineering </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Machine Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Machine Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../ml/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../ml/classifier/ class=md-nav__link> <span class=md-ellipsis> Classifier </span> </a> </li> <li class=md-nav__item> <a href=../../ml/unsupervised/ class=md-nav__link> <span class=md-ellipsis> Unsupervised Learning </span> </a> </li> <li class=md-nav__item> <a href=../../anomaly/ class=md-nav__link> <span class=md-ellipsis> Anomaly detection </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_5> <label class=md-nav__link for=__nav_2_5 id=__nav_2_5_label tabindex=0> <span class=md-ellipsis> Deep Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_5_label aria-expanded=false> <label class=md-nav__title for=__nav_2_5> <span class="md-nav__icon md-icon"></span> Deep Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../ml/deep-learning/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../ml/nlp/ class=md-nav__link> <span class=md-ellipsis> NLP </span> </a> </li> <li class=md-nav__item> <a href=../ddp/ class=md-nav__link> <span class=md-ellipsis> Distributed Data Parallel </span> </a> </li> <li class=md-nav__item> <a href=../../neuro-symbolic/ class=md-nav__link> <span class=md-ellipsis> Hybrid AI </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_6> <label class=md-nav__link for=__nav_2_6 id=__nav_2_6_label tabindex=0> <span class=md-ellipsis> Generative AI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_6_label aria-expanded=false> <label class=md-nav__title for=__nav_2_6> <span class="md-nav__icon md-icon"></span> Generative AI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../genAI/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/review/ class=md-nav__link> <span class=md-ellipsis> Skill set </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/prompt-eng/ class=md-nav__link> <span class=md-ellipsis> Prompt Engineering </span> </a> </li> <li class=md-nav__item> <a href=../../architecture/sol-design/ class=md-nav__link> <span class=md-ellipsis> Solution Design </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/rag/ class=md-nav__link> <span class=md-ellipsis> RAG </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/agentic/ class=md-nav__link> <span class=md-ellipsis> Agents </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/anthropic/ class=md-nav__link> <span class=md-ellipsis> Anthropic </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/openai/ class=md-nav__link> <span class=md-ellipsis> OpenAI </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/mistral/ class=md-nav__link> <span class=md-ellipsis> Mistral </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/cohere/ class=md-nav__link> <span class=md-ellipsis> Cohere </span> </a> </li> <li class=md-nav__item> <a href=../../techno/watsonx/ class=md-nav__link> <span class=md-ellipsis> WatsonX.ai </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Techno </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Techno </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../techno/airflow/ class=md-nav__link> <span class=md-ellipsis> Airflow </span> </a> </li> <li class=md-nav__item> <a href=../../techno/feature_store/ class=md-nav__link> <span class=md-ellipsis> Feature Store </span> </a> </li> <li class=md-nav__item> <a href=../../kaggle/ class=md-nav__link> <span class=md-ellipsis> Kaggle </span> </a> </li> <li class=md-nav__item> <a href=../../techno/opensearch/ class=md-nav__link> <span class=md-ellipsis> OpenSearch </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/python-code/ class=md-nav__link> <span class=md-ellipsis> Python studies </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/yarfba/ai-ml/sagemaker class=md-nav__link> <span class=md-ellipsis> SageMaker </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/spark-studies/ class=md-nav__link> <span class=md-ellipsis> Spark studies </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_8> <label class=md-nav__link for=__nav_3_8 id=__nav_3_8_label tabindex=0> <span class=md-ellipsis> UI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_8_label aria-expanded=false> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> UI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../techno/gradio/ class=md-nav__link> <span class=md-ellipsis> Gradio </span> </a> </li> <li class=md-nav__item> <a href=../../techno/streamlit/ class=md-nav__link> <span class=md-ellipsis> Streamlit </span> </a> </li> <li class=md-nav__item> <a href=../../techno/taipy/ class=md-nav__link> <span class=md-ellipsis> TaiPy </span> </a> </li> <li class=md-nav__item> <a href=../../techno/nicegui/ class=md-nav__link> <span class=md-ellipsis> NiceGUI </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../techno/gcp/ class=md-nav__link> <span class=md-ellipsis> GCP </span> </a> </li> <li class=md-nav__item> <a href=../../techno/watsonx/ class=md-nav__link> <span class=md-ellipsis> WatsonX.ai </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex> <span class=md-ellipsis> Coding </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Coding </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> <span class=md-ellipsis> Coding getting started </span> </a> </li> <li class=md-nav__item> <a href=../visualization/ class=md-nav__link> <span class=md-ellipsis> Data Visualization </span> </a> </li> <li class=md-nav__item> <a href=../haystack/ class=md-nav__link> <span class=md-ellipsis> Haystack.ai </span> </a> </li> <li class=md-nav__item> <a href=../langchain/ class=md-nav__link> <span class=md-ellipsis> LangChain </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> LangGraph </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> LangGraph </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#value-propositions class=md-nav__link> <span class=md-ellipsis> Value propositions </span> </a> </li> <li class=md-nav__item> <a href=#concepts class=md-nav__link> <span class=md-ellipsis> Concepts </span> </a> <nav class=md-nav aria-label=Concepts> <ul class=md-nav__list> <li class=md-nav__item> <a href=#agents class=md-nav__link> <span class=md-ellipsis> Agents </span> </a> </li> <li class=md-nav__item> <a href=#tool-calling class=md-nav__link> <span class=md-ellipsis> Tool Calling </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#use-cases class=md-nav__link> <span class=md-ellipsis> Use cases </span> </a> <nav class=md-nav aria-label="Use cases"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#reasoning-and-acting-react-implementation class=md-nav__link> <span class=md-ellipsis> Reasoning and Acting (ReAct) implementation </span> </a> </li> <li class=md-nav__item> <a href=#adaptive-rag class=md-nav__link> <span class=md-ellipsis> Adaptive RAG </span> </a> </li> <li class=md-nav__item> <a href=#human-in-the-loop class=md-nav__link> <span class=md-ellipsis> Human in the loop </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#other-code class=md-nav__link> <span class=md-ellipsis> Other Code </span> </a> </li> <li class=md-nav__item> <a href=#code-faq class=md-nav__link> <span class=md-ellipsis> Code FAQ </span> </a> </li> <li class=md-nav__item> <a href=#deeper-dive class=md-nav__link> <span class=md-ellipsis> Deeper dive </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../llama-index/ class=md-nav__link> <span class=md-ellipsis> LlamaIndex </span> </a> </li> <li class=md-nav__item> <a href=../pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../pytorch/ class=md-nav__link> <span class=md-ellipsis> PyTorch </span> </a> </li> <li class=md-nav__item> <a href=../sklearn/ class=md-nav__link> <span class=md-ellipsis> Scikit-learn </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Solutions </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Solutions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../solutions/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../techno/players_to_look/ class=md-nav__link> <span class=md-ellipsis> Key AI startups </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#value-propositions class=md-nav__link> <span class=md-ellipsis> Value propositions </span> </a> </li> <li class=md-nav__item> <a href=#concepts class=md-nav__link> <span class=md-ellipsis> Concepts </span> </a> <nav class=md-nav aria-label=Concepts> <ul class=md-nav__list> <li class=md-nav__item> <a href=#agents class=md-nav__link> <span class=md-ellipsis> Agents </span> </a> </li> <li class=md-nav__item> <a href=#tool-calling class=md-nav__link> <span class=md-ellipsis> Tool Calling </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#use-cases class=md-nav__link> <span class=md-ellipsis> Use cases </span> </a> <nav class=md-nav aria-label="Use cases"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#reasoning-and-acting-react-implementation class=md-nav__link> <span class=md-ellipsis> Reasoning and Acting (ReAct) implementation </span> </a> </li> <li class=md-nav__item> <a href=#adaptive-rag class=md-nav__link> <span class=md-ellipsis> Adaptive RAG </span> </a> </li> <li class=md-nav__item> <a href=#human-in-the-loop class=md-nav__link> <span class=md-ellipsis> Human in the loop </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#other-code class=md-nav__link> <span class=md-ellipsis> Other Code </span> </a> </li> <li class=md-nav__item> <a href=#code-faq class=md-nav__link> <span class=md-ellipsis> Code FAQ </span> </a> </li> <li class=md-nav__item> <a href=#deeper-dive class=md-nav__link> <span class=md-ellipsis> Deeper dive </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=langgraph>LangGraph<a class=headerlink href=#langgraph title="Permanent link">&para;</a></h1> <div class="admonition - info"> <p class=admonition-title>Updates</p> <p>Created 04/2024 - Update 09/21/2024</p> </div> <p><a href=https://python.langchain.com/docs/langgraph>LangGraph</a> is a library for building stateful, <strong>multi-actor</strong> applications, and being able to add cycles to LLM app. It is not a DAG. </p> <p>Single and multi-agent flows are described and represented as graphs.</p> <h2 id=value-propositions>Value propositions<a class=headerlink href=#value-propositions title="Permanent link">&para;</a></h2> <ul> <li>Build stateful, multi-actor applications with LLMs</li> <li>Coordinate multiple chains or actors across multiple steps of computation in a cyclic manner</li> <li>Build plan of the actions to take</li> <li>Take the actions</li> <li>Observe the effects</li> <li>Support persistence to save state after each step in the graph. This allows human in the loop pattern</li> <li>Support Streaming agent tokens and node transitions</li> </ul> <h2 id=concepts><a href=https://langchain-ai.github.io/langgraph/concepts/ >Concepts</a><a class=headerlink href=#concepts title="Permanent link">&para;</a></h2> <p><a href=https://python.langchain.com/docs/langgraph/#stategraph>States</a> may be a collection of messages or custom states as defined by a TypedDict schema. States are passed between nodes of the graph. MessageState is a predefined state to include the list of messages.</p> <p><code>Nodes</code> represent units of work. It can be either a function or a runnable. Each node updates the internal graph state and returns it after execution.</p> <p><code>Graph</code> defines the organization of the node workflow. Graphs are immutable so are compiled once defined:</p> <div class=highlight><span class=filename>A simple call LLM graph</span><pre><span></span><code><span class=n>graph</span> <span class=o>=</span> <span class=n>MessageGraph</span><span class=p>()</span>

<span class=n>graph</span><span class=o>.</span><span class=n>add_node</span><span class=p>(</span><span class=s2>&quot;chatbot&quot;</span><span class=p>,</span> <span class=n>chatbot_func</span><span class=p>)</span>  <span class=c1># (1)</span>
<span class=n>graph</span><span class=o>.</span><span class=n>add_edge</span><span class=p>(</span><span class=s2>&quot;chatbot&quot;</span><span class=p>,</span> <span class=n>END</span><span class=p>)</span>

<span class=n>graph</span><span class=o>.</span><span class=n>set_entry_point</span><span class=p>(</span><span class=s2>&quot;chatbot&quot;</span><span class=p>)</span>

<span class=n>runnable</span> <span class=o>=</span> <span class=n>graph</span><span class=o>.</span><span class=n>compile</span><span class=p>()</span>
</code></pre></div> <ol> <li>chatbot_func is a function to call a LLM. <code>add_node()</code> takes a <strong>function or runnable</strong>, with the input is the entire current state:</li> </ol> <p>See <a href=https://github.com/jbcodeforce/ML-studies/blob/master/llm-langchain/langgraph/FirstGraphOnlyLLM.py>FirstGraphOnlyLLM.py</a></p> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>call_tool</span><span class=p>(</span><span class=n>state</span><span class=p>):</span>  <span class=c1># (1)</span>
    <span class=n>messages</span> <span class=o>=</span> <span class=n>state</span><span class=p>[</span><span class=s2>&quot;messages&quot;</span><span class=p>]</span>
    <span class=n>last_message</span> <span class=o>=</span> <span class=n>messages</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
    <span class=c1>#...</span>
</code></pre></div> <ol> <li>The State of the graph, in this case, includes a list of messages</li> </ol> <p><strong>Conditional edge</strong> between nodes, helps to build more flexible workflow: based on the output of a node, one of several paths may be taken. Conditional edge use function to decide where to route according to the last message content.</p> <div class=highlight><pre><span></span><code><span class=n>workflow</span><span class=o>.</span><span class=n>add_conditional_edges</span><span class=p>(</span>
                <span class=s2>&quot;agent&quot;</span><span class=p>,</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>should_continue</span><span class=p>,</span>
                <span class=p>{</span>
                    <span class=s2>&quot;continue&quot;</span><span class=p>:</span> <span class=s2>&quot;action&quot;</span><span class=p>,</span>
                    <span class=s2>&quot;end&quot;</span><span class=p>:</span> <span class=n>END</span><span class=p>,</span>
                <span class=p>},</span>
            <span class=p>)</span>
</code></pre></div> <h3 id=agents>Agents<a class=headerlink href=#agents title="Permanent link">&para;</a></h3> <p>Graphs helps implementing Agents as AgentExecutor is a deprecated API. They most likely use tools. The graph development approach is:</p> <ol> <li>Define the tools to be used</li> <li>Define the state and what needs to be persisted</li> <li> <p>Define the workflow as a graph, and the persistence mechanism to use when needed, compile the graph into a LangChain Runnable. Once the graph is compiled, the application can interact with the graph via stream or invoke methods.</p> <div class=highlight><pre><span></span><code><span class=n>app</span> <span class=o>=</span> <span class=n>workflow</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>checkpointer</span><span class=o>=</span><span class=n>checkpointer</span><span class=p>)</span>
</code></pre></div> </li> <li> <p>Invoke the graph as part of an API, an integrated ChatBot, using a dict including the parameter of the State...</p> </li> </ol> <p>Graphs such as StateGraph's naturally can be composed. Creating subgraphs lets developers build things like multi-agent teams, where each team can track its own separate state.</p> <p>LangGraph comes with built-in persistence, allowing developers to save the state of the graph at a given point and resume from there <a href="https://langchain-ai.github.io/langgraph/reference/checkpoints/?h=sqlite+saver#memorysaver">MemorySaver</a>, <a href="https://langchain-ai.github.io/langgraph/reference/checkpoints/?h=sqlite+saver#postgressaver">Postgresql</a>, <a href="https://langchain-ai.github.io/langgraph/reference/checkpoints/?h=sqlite+saver#sqlitesaver">SqliteSaver</a>.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>langgraph.checkpoint.memory</span><span class=w> </span><span class=kn>import</span> <span class=n>MemorySaver</span>

<span class=n>memory</span> <span class=o>=</span> <span class=n>MemorySaver</span><span class=p>()</span>
<span class=n>app</span> <span class=o>=</span> <span class=n>workflow</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>checkpointer</span><span class=o>=</span><span class=n>memory</span><span class=p>,</span> <span class=n>interrupt_before</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;action&quot;</span><span class=p>])</span>
</code></pre></div> <p>When using checkpointing the invoke method needs to get a configuration parameter with a unique thread_id to group messages and checkpoints in the context of this thread_id:</p> <div class=highlight><pre><span></span><code><span class=n>thread</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&quot;configurable&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;thread_id&quot;</span><span class=p>:</span> <span class=s2>&quot;2&quot;</span><span class=p>}}</span>
<span class=k>for</span> <span class=n>event</span> <span class=ow>in</span> <span class=n>app</span><span class=o>.</span><span class=n>stream</span><span class=p>({</span><span class=s2>&quot;messages&quot;</span><span class=p>:</span> <span class=n>inputs</span><span class=p>},</span> <span class=n>thread</span><span class=p>,</span> <span class=n>stream_mode</span><span class=o>=</span><span class=s2>&quot;values&quot;</span><span class=p>):</span>  <span class=c1># (1)</span>
</code></pre></div> <ol> <li>Call the graph using streaming do event are yielded.</li> </ol> <p>See <a href=https://langchain-ai.github.io/langgraph/reference/checkpoints/#implementations>other checkpointer ways to persist state</a>, <a href=https://langchain-ai.github.io/langgraph/reference/checkpoints/#asyncsqlitesaver>AsyncSqliteSaver</a> is an asynchronous checkpoint saver that stores checkpoints in a SQLite database or <a href=https://langchain-ai.github.io/langgraph/reference/checkpoints/#sqlitesaver>SqliteSaver</a> for synchronous storage is SQLlite.</p> <div class=highlight><pre><span></span><code><span class=n>memory</span> <span class=o>=</span> <span class=n>AsyncSqliteSaver</span><span class=o>.</span><span class=n>from_conn_string</span><span class=p>(</span><span class=s2>&quot;checkpoints.sqlite&quot;</span><span class=p>)</span>
</code></pre></div> <ul> <li>See <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/FirstGraphOnlyLLM.py>first basic program</a> or the <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/FirstGraphWithTool.py>one with tool</a> to call Tavily tool for searching recent information about the weather in San Francisco using OpenAI LLM. (it is based on the <a href=https://langchain-ai.github.io/langgraph/#example>tutorial</a>). It does not use any prompt, and the call_method function invokes OpenAI model directly.</li> </ul> <h4 id=invocation-and-chat-history>Invocation and chat history<a class=headerlink href=#invocation-and-chat-history title="Permanent link">&para;</a></h4> <p>The LangGraph's <code>MessageState</code> keeps an array of messages. So the input is a dict with the "messages" key and then a HumanMessage, ToolMessage or AIMessage. As graphs are stateful, it is important to pass a thread_id, which should be unique per user's chat conversation.</p> <div class=highlight><pre><span></span><code><span class=n>app</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span>
    <span class=p>{</span><span class=s2>&quot;messages&quot;</span><span class=p>:</span> <span class=p>[</span><span class=n>HumanMessage</span><span class=p>(</span><span class=n>content</span><span class=o>=</span><span class=s2>&quot;what is the weather in sf&quot;</span><span class=p>)]},</span>
    <span class=n>config</span><span class=o>=</span><span class=p>{</span><span class=s2>&quot;configurable&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;thread_id&quot;</span><span class=p>:</span> <span class=s2>&quot;42&quot;</span><span class=p>}},</span> <span class=n>debug</span><span class=o>=</span><span class=kc>True</span>
<span class=p>)</span>
</code></pre></div> <p>Some code using chat_history:</p> <ul> <li> <p>A simple version with tool and memory using prebuilt LangGraph constructs <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/FirstGraphWithToolAndMemory.py>FirstGraphWithToolAndMemory.py</a></p> </li> <li> <p><a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/close_question.py>Close Question with a node creating a close question and then processes the outcome with llm</a>.</p> </li> </ul> <p><img alt src=../diagrams/close_q.drawio.png></p> <p>The LLM execution trace presents the following content:</p> <div class=highlight><pre><span></span><code><span class=w> </span><span class=err>E</span><span class=kc>nter</span><span class=err>i</span><span class=kc>n</span><span class=err>g</span><span class=w> </span><span class=err>LLM</span><span class=w> </span><span class=err>ru</span><span class=kc>n</span><span class=w> </span><span class=err>wi</span><span class=kc>t</span><span class=err>h</span><span class=w> </span><span class=err>i</span><span class=kc>n</span><span class=err>pu</span><span class=kc>t</span><span class=p>:</span>
<span class=p>{</span>
<span class=w>  </span><span class=nt>&quot;prompts&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=s2>&quot;Human: what is the weather in sf&quot;</span>
<span class=w>  </span><span class=p>]</span>
<span class=p>}</span>
</code></pre></div> <p>The LLM is generating some statements that tool calling is needed by matching to the tool name specified (e.g. <code>tavily_search_results_json</code>) during LLM creation (with the args coming from the function signature or for a schema definition as part of the tool definition). Below is an example of OpenAI tool_calls response. Most LLMs support this schema:</p> <div class=highlight><pre><span></span><code><span class=nt>&quot;generations&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=p>[</span>
<span class=w>      </span><span class=p>{</span>
<span class=w>        </span><span class=nt>&quot;text&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;&quot;</span><span class=p>,</span>
<span class=w>        </span><span class=nt>&quot;generation_info&quot;</span><span class=p>:</span><span class=w> </span><span class=p>{</span>
<span class=w>          </span><span class=nt>&quot;finish_reason&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;tool_calls&quot;</span><span class=p>,</span>
<span class=w>          </span><span class=err>...</span>
<span class=w>        </span><span class=nt>&quot;tool_calls&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>            </span><span class=p>{</span>
<span class=w>            </span><span class=nt>&quot;name&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;tavily_search_results_json&quot;</span><span class=p>,</span>
<span class=w>            </span><span class=nt>&quot;args&quot;</span><span class=p>:</span><span class=w> </span><span class=p>{</span>
<span class=w>                </span><span class=nt>&quot;query&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;weather in San Francisco&quot;</span>
<span class=w>            </span><span class=p>},</span>
<span class=w>            </span><span class=nt>&quot;id&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;call_Vg6JRaaz8d06OXbG5Gv7Ea5J&quot;</span>
<span class=w>            </span><span class=p>}</span>
</code></pre></div> <p>Graph cycles the steps until there are no more <code>tool_calls</code> within the AIMessage: 1/ If AIMessage has tool_calls, "tools" node executes the matching function, 2/ the "agent" node executes again and returns AIMessage. Execution progresses to the special <code>END</code> value and outputs the final state</p> <p>Adding a "chat memory" to the graph with LangGraph's checkpointer to retain the chat context between interactions.</p> <h3 id=tool-calling>Tool Calling<a class=headerlink href=#tool-calling title="Permanent link">&para;</a></h3> <p>The Graph must include <code>ToolNode</code> to call the slected function or tool which can be called via conditions on edge. The following declaration uses the predefined langchain tool definition of TavilySearch. The <code>TavilySearchResults</code> has function name, argument schema and tool definition so the prompt sent to LLM has information about the tool like: "name": "tavily_search_results_json"</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>langchain_community.tools.tavily_search</span><span class=w> </span><span class=kn>import</span> <span class=n>TavilySearchResults</span>
<span class=n>tools</span> <span class=o>=</span> <span class=p>[</span><span class=n>TavilySearchResults</span><span class=p>(</span><span class=n>max_results</span><span class=o>=</span><span class=mi>2</span><span class=p>)]</span>
<span class=n>tool_node</span> <span class=o>=</span> <span class=n>ToolNode</span><span class=p>(</span><span class=n>tools</span><span class=p>)</span>
</code></pre></div> <h4 id=tool-calling-with-mistral>Tool calling with Mistral<a class=headerlink href=#tool-calling-with-mistral title="Permanent link">&para;</a></h4> <p>See <a href=https://docs.mistral.ai/capabilities/function_calling/ >this product documentation</a> adapted to langgraph in <a href=https://github.com/jbcodeforce/ML-studies/blob/master/llm-langchain/mistral/mistral_tool_calling_lg.py>this code</a> and <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/mistral_lg_tool.py>this new LangGraph API with ToolNode, and ChatMistral with bind_tools</a>.</p> <h2 id=use-cases>Use cases<a class=headerlink href=#use-cases title="Permanent link">&para;</a></h2> <p>The interesting use cases for LangGraph are:</p> <ul> <li>workflow with cycles and conditional output</li> <li>planning agent for plan and execute pattern</li> <li>using reflection and self critique</li> <li>multi agent collaboration, with or without supervisor</li> <li>human in the loop (by adding an "interrupt" before a node is executed.)</li> <li>controlled tool calling with or without LLM output</li> </ul> <h3 id=reasoning-and-acting-react-implementation>Reasoning and Acting (ReAct) implementation<a class=headerlink href=#reasoning-and-acting-react-implementation title="Permanent link">&para;</a></h3> <p>See <a href=https://til.simonwillison.net/llms/python-react-pattern>this paper: A simple Python implementation of the ReAct pattern for LLMs</a> from Simon Willison, and the raw code implementation using openAI API <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/ReAct.py>code: ReAct.py</a>. LangGraph uses a <a href=https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent>prebuilt implementation of ReAct</a> that can be tested by <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/PreBuilt_ReAct_lg.py>PreBuilt_ReAct_lg.py</a> or the <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/ReAct_lg.py>implementation of ReAct pattern using LangGraph</a>.</p> <p>An interesting prompt to use in the ReAct implementation is <a href=https://smith.langchain.com/hub/hwchase17/react>hwchase17/react</a>.</p> <p>It is possible to interrupt before or after a node.</p> <div class=highlight><pre><span></span><code><span class=n>graph</span> <span class=o>=</span> <span class=n>create_react_agent</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>tools</span><span class=o>=</span><span class=n>tools</span><span class=p>,</span> <span class=n>interrupt_before</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;tools&quot;</span><span class=p>],</span>  <span class=n>checkpointer</span><span class=o>=</span><span class=n>memory</span><span class=p>)</span>
<span class=n>print_stream</span><span class=p>(</span><span class=n>graph</span><span class=p>,</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>thread</span><span class=p>)</span>
<span class=c1># the graph ended because of the interrupt</span>
<span class=n>snapshot</span> <span class=o>=</span> <span class=n>graph</span><span class=o>.</span><span class=n>get_state</span><span class=p>(</span><span class=n>thread</span><span class=p>)</span>  <span class=c1># got where it was stopped</span>
</code></pre></div> <p>See <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/mistral_lg_tool.py>The most simple ReAct with Mistral Model</a></p> <h3 id=adaptive-rag>Adaptive RAG<a class=headerlink href=#adaptive-rag title="Permanent link">&para;</a></h3> <p>The code <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/adaptive_rag.py>adaptive_rag.py</a> is implementing the following graph as documented in <a href=https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_adaptive_rag/ >this sample from product documentation</a>: </p> <p><img alt src=../diagrams/adaptive_rag.drawio.png></p> <p>The documents processing and vector store creation is done in separate function outside of the graph.</p> <p>Some interesting patterns from this sample:</p> <ul> <li>One Agent to route the query, with dedicated prompt </li> <li>retriever from vector store with an agent to grade the retrieved documents</li> <li>graph state includes question, retrieved documents </li> </ul> <h3 id=human-in-the-loop>Human in the loop<a class=headerlink href=#human-in-the-loop title="Permanent link">&para;</a></h3> <p>The human is the loop can be implemented in different ways:</p> <ul> <li>Add a confirmation before invoking a tool, using the the interrupt_before the names of the tool. <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/human_in_loop.py>See human_in_loop.py</a></li> <li>Implementing a human node before which the graph will always stop <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/ask_human_graph.py>ask_human_graph.py</a></li> </ul> <p>See <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/prompt_builder_graph.py>prompt_builder_graph</a> which is also integrated with Taipy UI in <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/chatbot_graph_ui.py>Taipy UI with a langgraph graph</a></p> <h2 id=other-code>Other Code<a class=headerlink href=#other-code title="Permanent link">&para;</a></h2> <p>See <a href=https://github.com/langchain-ai/langgraph/tree/main/examples>Langgraph code samples</a> with interesting patterns, but with some code not following the last updates in the APIs and my <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph>own sample folder</a>. </p> <p>See the <a href=https://athenadecisionsystems.github.io/athena-owl-core/ >owl agent framework open source project</a> to manage assistant, agents, tools, prompts..</p> <h2 id=code-faq>Code FAQ<a class=headerlink href=#code-faq title="Permanent link">&para;</a></h2> <details class="- question"> <summary>prompt variables to be integrated in LangGraph</summary> <p>The graph state should include variables used in the prompts used in the agents.</p> </details> <details class="- question"> <summary>Streaming the output?</summary> <p>Each node with LLM agent needs to call an async function.</p> <div class=highlight><pre><span></span><code><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>call_agent</span><span class=p>(</span><span class=n>state</span><span class=p>:</span> <span class=n>State</span><span class=p>)</span>
  <span class=c1># ... process the state</span>
  <span class=n>response</span> <span class=o>=</span> <span class=k>await</span> <span class=n>model</span><span class=o>.</span><span class=n>ainvoke</span><span class=p>(</span><span class=n>messages</span><span class=p>)</span>
</code></pre></div> <p>Once the graph is created, the application needs to invoke it with an <code>async for</code></p> <div class=highlight><pre><span></span><code><span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>text_chat</span><span class=p>(</span><span class=n>graph</span><span class=p>):</span>
<span class=n>config</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&quot;configurable&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;thread_id&quot;</span><span class=p>:</span> <span class=mi>1</span><span class=p>}}</span>

<span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
    <span class=n>user_msg</span> <span class=o>=</span> <span class=nb>input</span><span class=p>(</span><span class=s2>&quot;User (q/Q to quit): &quot;</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>user_msg</span> <span class=ow>in</span> <span class=p>{</span><span class=s2>&quot;q&quot;</span><span class=p>,</span> <span class=s2>&quot;Q&quot;</span><span class=p>}:</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;AI: Byebye&quot;</span><span class=p>)</span>
        <span class=k>break</span>
    <span class=k>async</span> <span class=k>for</span> <span class=n>event</span> <span class=ow>in</span> <span class=n>graph</span><span class=o>.</span><span class=n>astream_events</span><span class=p>({</span><span class=s2>&quot;messages&quot;</span><span class=p>:</span> <span class=p>[</span><span class=n>HumanMessage</span><span class=p>(</span><span class=n>content</span><span class=o>=</span><span class=n>user_msg</span><span class=p>)]},</span> <span class=n>version</span><span class=o>=</span><span class=s2>&quot;v1&quot;</span><span class=p>):</span>
        <span class=o>...</span> <span class=n>process</span> <span class=n>the</span> <span class=n>event</span> <span class=n>payload</span>
</code></pre></div> <p>See <a href=https://github.com/jbcodeforce/ML-studies/tree/master/llm-langchain/langgraph/stream_agent_node.py>stream_agent_node.py</a> and the one with a simple UI <a href=https://github.com/jbcodeforce/ML-studies/tree/master/e2e-demos/streaming-demo/main_lg.py>with websocket and langgraph</a></p> </details> <details class="- question"> <summary>How to do close question?</summary> </details> <details class="- question"> <summary>How to do classification of intent?</summary> <p>Use a system prompt with possible classification values, and one agent in one node of the graph. Then in the conditional edge function, test to the different value to branch in different paths.</p> </details> <h2 id=deeper-dive>Deeper dive<a class=headerlink href=#deeper-dive title="Permanent link">&para;</a></h2> <ul> <li><a href=https://langchain-ai.github.io/langgraph/reference/prebuilt/ >LangGraph product reference documentation.</a></li> <li><a href=https://github.com/langchain-ai/langgraph>LangGraph git repository</a></li> <li><a href=https://langchain-ai.github.io/langgraph/reference/graphs/ >LangGraph API reference guide</a></li> <li><a href=https://learn.deeplearning.ai/courses/ai-agents-in-langgraph>Deeplearning.ai AI Agents in LangGraph</a> with matching code </li> <li><a href=https://til.simonwillison.net/llms/python-react-pattern>A simple Python implementation of the ReAct pattern for LLMs</a></li> </ul> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../langchain/ class="md-footer__link md-footer__link--prev" aria-label="Previous: LangChain"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> LangChain </div> </div> </a> <a href=../llama-index/ class="md-footer__link md-footer__link--next" aria-label="Next: LlamaIndex"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> LlamaIndex </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2018 - 2024 Jerome Boyer </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/jbcodeforce target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://linkedin.com/in/jeromeboyer target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> <a href target=_blank rel=noopener title class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M536.4-26.3c9.8-3.5 20.6-1 28 6.3s9.8 18.2 6.3 28l-178 496.9c-5 13.9-18.1 23.1-32.8 23.1-14.2 0-27-8.6-32.3-21.7l-64.2-158c-4.5-11-2.5-23.6 5.2-32.6l94.5-112.4c5.1-6.1 4.7-15-.9-20.6s-14.6-6-20.6-.9l-112.4 94.3c-9.1 7.6-21.6 9.6-32.6 5.2L38.1 216.8c-13.1-5.3-21.7-18.1-21.7-32.3 0-14.7 9.2-27.8 23.1-32.8z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "content.code.copy", "content.tooltips", "content.code.copy", "search.highlight", "navigation.instant", "navigation.instant.progress", "navigation.tabs", "navigation.tabs.sticky", "navigation.instant", "navigation.tracking", "navigation.top", "navigation.footer"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.92b07e13.min.js></script> </body> </html>