<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=https://jeromeboyer.net/ML-studies/coding/pytorch/ rel=canonical><link href=../pandas/ rel=prev><link href=../sklearn/ rel=next><link rel=icon href=../../assets/logo.drawio.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.18"><title>PyTorch - Machine Learning Studies - Jerome Boyer</title><link rel=stylesheet href=../../assets/stylesheets/main.7e37652d.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#pytorch-library class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Machine Learning Studies - Jerome Boyer" class="md-header__button md-logo" aria-label="Machine Learning Studies - Jerome Boyer" data-md-component=logo> <img src=../../assets/logo.drawio.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Machine Learning Studies - Jerome Boyer </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> PyTorch </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/jbcodeforce/ML-studies title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> About </a> </li> <li class=md-tabs__item> <a href=../../ml/ class=md-tabs__link> Machine Learning </a> </li> <li class=md-tabs__item> <a href=../../techno/airflow/ class=md-tabs__link> Techno </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> Coding </a> </li> <li class=md-tabs__item> <a href=../../solutions/ class=md-tabs__link> Solutions </a> </li> <li class=md-tabs__item> <a href=https://jbcodeforce.github.io class=md-tabs__link> Home </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Machine Learning Studies - Jerome Boyer" class="md-nav__button md-logo" aria-label="Machine Learning Studies - Jerome Boyer" data-md-component=logo> <img src=../../assets/logo.drawio.png alt=logo> </a> Machine Learning Studies - Jerome Boyer </label> <div class=md-nav__source> <a href=https://github.com/jbcodeforce/ML-studies title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <label class=md-nav__link for=__nav_1 id=__nav_1_label tabindex=0> <span class=md-ellipsis> About </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> About </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_2> <label class=md-nav__link for=__nav_1_2 id=__nav_1_2_label tabindex=0> <span class=md-ellipsis> Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_1_2> <span class="md-nav__icon md-icon"></span> Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../concepts/ class=md-nav__link> <span class=md-ellipsis> Core concepts </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/maths/ class=md-nav__link> <span class=md-ellipsis> Math summary </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/skill/ class=md-nav__link> <span class=md-ellipsis> Data scientist skill </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_3> <label class=md-nav__link for=__nav_1_3 id=__nav_1_3_label tabindex=0> <span class=md-ellipsis> Architecture </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_3_label aria-expanded=false> <label class=md-nav__title for=__nav_1_3> <span class="md-nav__icon md-icon"></span> Architecture </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../architecture/sol-design/ class=md-nav__link> <span class=md-ellipsis> Solution Design </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_4> <label class=md-nav__link for=__nav_1_4 id=__nav_1_4_label tabindex=0> <span class=md-ellipsis> Data management </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_1_4> <span class="md-nav__icon md-icon"></span> Data management </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../data/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../data/features/ class=md-nav__link> <span class=md-ellipsis> Feature Engineering </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Machine Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Machine Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../ml/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../ml/classifier/ class=md-nav__link> <span class=md-ellipsis> Classifier </span> </a> </li> <li class=md-nav__item> <a href=../../ml/unsupervised/ class=md-nav__link> <span class=md-ellipsis> Unsupervised Learning </span> </a> </li> <li class=md-nav__item> <a href=../../anomaly/ class=md-nav__link> <span class=md-ellipsis> Anomaly detection </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_5> <label class=md-nav__link for=__nav_2_5 id=__nav_2_5_label tabindex=0> <span class=md-ellipsis> Deep Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_5_label aria-expanded=false> <label class=md-nav__title for=__nav_2_5> <span class="md-nav__icon md-icon"></span> Deep Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../ml/deep-learning/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../ml/nlp/ class=md-nav__link> <span class=md-ellipsis> NLP </span> </a> </li> <li class=md-nav__item> <a href=../ddp/ class=md-nav__link> <span class=md-ellipsis> Distributed Data Parallel </span> </a> </li> <li class=md-nav__item> <a href=../../neuro-symbolic/ class=md-nav__link> <span class=md-ellipsis> Hybrid AI </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_6> <label class=md-nav__link for=__nav_2_6 id=__nav_2_6_label tabindex=0> <span class=md-ellipsis> Generative AI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_6_label aria-expanded=false> <label class=md-nav__title for=__nav_2_6> <span class="md-nav__icon md-icon"></span> Generative AI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../genAI/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/review/ class=md-nav__link> <span class=md-ellipsis> Skill set </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/prompt-eng/ class=md-nav__link> <span class=md-ellipsis> Prompt Engineering </span> </a> </li> <li class=md-nav__item> <a href=../../architecture/sol-design/ class=md-nav__link> <span class=md-ellipsis> Solution Design </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/rag/ class=md-nav__link> <span class=md-ellipsis> RAG </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/agentic/ class=md-nav__link> <span class=md-ellipsis> Agents </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/anthropic/ class=md-nav__link> <span class=md-ellipsis> Anthropic </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/openai/ class=md-nav__link> <span class=md-ellipsis> OpenAI </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/mistral/ class=md-nav__link> <span class=md-ellipsis> Mistral </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/cohere/ class=md-nav__link> <span class=md-ellipsis> Cohere </span> </a> </li> <li class=md-nav__item> <a href=../../techno/watsonx/ class=md-nav__link> <span class=md-ellipsis> WatsonX.ai </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Techno </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Techno </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../techno/airflow/ class=md-nav__link> <span class=md-ellipsis> Airflow </span> </a> </li> <li class=md-nav__item> <a href=../../techno/feature_store/ class=md-nav__link> <span class=md-ellipsis> Feature Store </span> </a> </li> <li class=md-nav__item> <a href=../../kaggle/ class=md-nav__link> <span class=md-ellipsis> Kaggle </span> </a> </li> <li class=md-nav__item> <a href=../../techno/opensearch/ class=md-nav__link> <span class=md-ellipsis> OpenSearch </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/python-code/ class=md-nav__link> <span class=md-ellipsis> Python studies </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/yarfba/ai-ml/sagemaker class=md-nav__link> <span class=md-ellipsis> SageMaker </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/spark-studies/ class=md-nav__link> <span class=md-ellipsis> Spark studies </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_8> <label class=md-nav__link for=__nav_3_8 id=__nav_3_8_label tabindex=0> <span class=md-ellipsis> UI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_8_label aria-expanded=false> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> UI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../techno/gradio/ class=md-nav__link> <span class=md-ellipsis> Gradio </span> </a> </li> <li class=md-nav__item> <a href=../../techno/streamlit/ class=md-nav__link> <span class=md-ellipsis> Streamlit </span> </a> </li> <li class=md-nav__item> <a href=../../techno/taipy/ class=md-nav__link> <span class=md-ellipsis> TaiPy </span> </a> </li> <li class=md-nav__item> <a href=../../techno/nicegui/ class=md-nav__link> <span class=md-ellipsis> NiceGUI </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../techno/gcp/ class=md-nav__link> <span class=md-ellipsis> GCP </span> </a> </li> <li class=md-nav__item> <a href=../../techno/watsonx/ class=md-nav__link> <span class=md-ellipsis> WatsonX.ai </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex> <span class=md-ellipsis> Coding </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Coding </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> <span class=md-ellipsis> Coding getting started </span> </a> </li> <li class=md-nav__item> <a href=../visualization/ class=md-nav__link> <span class=md-ellipsis> Data Visualization </span> </a> </li> <li class=md-nav__item> <a href=../haystack/ class=md-nav__link> <span class=md-ellipsis> Haystack.ai </span> </a> </li> <li class=md-nav__item> <a href=../langchain/ class=md-nav__link> <span class=md-ellipsis> LangChain </span> </a> </li> <li class=md-nav__item> <a href=../langgraph/ class=md-nav__link> <span class=md-ellipsis> LangGraph </span> </a> </li> <li class=md-nav__item> <a href=../llama-index/ class=md-nav__link> <span class=md-ellipsis> LlamaIndex </span> </a> </li> <li class=md-nav__item> <a href=../pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> PyTorch </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> PyTorch </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#environment-setup class=md-nav__link> <span class=md-ellipsis> Environment setup </span> </a> <nav class=md-nav aria-label="Environment setup"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#install class=md-nav__link> <span class=md-ellipsis> Install </span> </a> </li> <li class=md-nav__item> <a href=#run-once-conda-installed class=md-nav__link> <span class=md-ellipsis> Run once conda installed </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#concepts class=md-nav__link> <span class=md-ellipsis> Concepts </span> </a> <nav class=md-nav aria-label=Concepts> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tensor class=md-nav__link> <span class=md-ellipsis> Tensor </span> </a> </li> <li class=md-nav__item> <a href=#constructs class=md-nav__link> <span class=md-ellipsis> Constructs </span> </a> </li> <li class=md-nav__item> <a href=#gpu class=md-nav__link> <span class=md-ellipsis> GPU </span> </a> </li> <li class=md-nav__item> <a href=#basic-algebra-with-pytorch class=md-nav__link> <span class=md-ellipsis> Basic Algebra with Pytorch </span> </a> </li> <li class=md-nav__item> <a href=#loss-functions class=md-nav__link> <span class=md-ellipsis> Loss functions </span> </a> </li> <li class=md-nav__item> <a href=#neural-network class=md-nav__link> <span class=md-ellipsis> Neural network </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#model-training class=md-nav__link> <span class=md-ellipsis> Model training </span> </a> <nav class=md-nav aria-label="Model training"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#pytorch-training-loop class=md-nav__link> <span class=md-ellipsis> PyTorch training loop </span> </a> </li> <li class=md-nav__item> <a href=#pytorch-testing-loop class=md-nav__link> <span class=md-ellipsis> PyTorch testing loop </span> </a> </li> <li class=md-nav__item> <a href=#improving-a-model class=md-nav__link> <span class=md-ellipsis> Improving a model </span> </a> </li> <li class=md-nav__item> <a href=#evaluate-classification-models class=md-nav__link> <span class=md-ellipsis> Evaluate classification models </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#pytorch-datasets class=md-nav__link> <span class=md-ellipsis> Pytorch datasets </span> </a> <nav class=md-nav aria-label="Pytorch datasets"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#data-augmentation class=md-nav__link> <span class=md-ellipsis> Data augmentation </span> </a> </li> <li class=md-nav__item> <a href=#transfer-learning-for-image-classification class=md-nav__link> <span class=md-ellipsis> Transfer learning for image classification </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#some-how-to class=md-nav__link> <span class=md-ellipsis> Some How to </span> </a> </li> <li class=md-nav__item> <a href=#code-samples class=md-nav__link> <span class=md-ellipsis> Code samples </span> </a> </li> <li class=md-nav__item> <a href=#resources class=md-nav__link> <span class=md-ellipsis> Resources </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../sklearn/ class=md-nav__link> <span class=md-ellipsis> Scikit-learn </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Solutions </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Solutions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../solutions/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../techno/players_to_look/ class=md-nav__link> <span class=md-ellipsis> Key AI startups </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#environment-setup class=md-nav__link> <span class=md-ellipsis> Environment setup </span> </a> <nav class=md-nav aria-label="Environment setup"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#install class=md-nav__link> <span class=md-ellipsis> Install </span> </a> </li> <li class=md-nav__item> <a href=#run-once-conda-installed class=md-nav__link> <span class=md-ellipsis> Run once conda installed </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#concepts class=md-nav__link> <span class=md-ellipsis> Concepts </span> </a> <nav class=md-nav aria-label=Concepts> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tensor class=md-nav__link> <span class=md-ellipsis> Tensor </span> </a> </li> <li class=md-nav__item> <a href=#constructs class=md-nav__link> <span class=md-ellipsis> Constructs </span> </a> </li> <li class=md-nav__item> <a href=#gpu class=md-nav__link> <span class=md-ellipsis> GPU </span> </a> </li> <li class=md-nav__item> <a href=#basic-algebra-with-pytorch class=md-nav__link> <span class=md-ellipsis> Basic Algebra with Pytorch </span> </a> </li> <li class=md-nav__item> <a href=#loss-functions class=md-nav__link> <span class=md-ellipsis> Loss functions </span> </a> </li> <li class=md-nav__item> <a href=#neural-network class=md-nav__link> <span class=md-ellipsis> Neural network </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#model-training class=md-nav__link> <span class=md-ellipsis> Model training </span> </a> <nav class=md-nav aria-label="Model training"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#pytorch-training-loop class=md-nav__link> <span class=md-ellipsis> PyTorch training loop </span> </a> </li> <li class=md-nav__item> <a href=#pytorch-testing-loop class=md-nav__link> <span class=md-ellipsis> PyTorch testing loop </span> </a> </li> <li class=md-nav__item> <a href=#improving-a-model class=md-nav__link> <span class=md-ellipsis> Improving a model </span> </a> </li> <li class=md-nav__item> <a href=#evaluate-classification-models class=md-nav__link> <span class=md-ellipsis> Evaluate classification models </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#pytorch-datasets class=md-nav__link> <span class=md-ellipsis> Pytorch datasets </span> </a> <nav class=md-nav aria-label="Pytorch datasets"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#data-augmentation class=md-nav__link> <span class=md-ellipsis> Data augmentation </span> </a> </li> <li class=md-nav__item> <a href=#transfer-learning-for-image-classification class=md-nav__link> <span class=md-ellipsis> Transfer learning for image classification </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#some-how-to class=md-nav__link> <span class=md-ellipsis> Some How to </span> </a> </li> <li class=md-nav__item> <a href=#code-samples class=md-nav__link> <span class=md-ellipsis> Code samples </span> </a> </li> <li class=md-nav__item> <a href=#resources class=md-nav__link> <span class=md-ellipsis> Resources </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=pytorch-library><a href=https://pytorch.org/ >Pytorch library</a><a class=headerlink href=#pytorch-library title="Permanent link">&para;</a></h1> <p>The <a href=https://paperswithcode.com/trends>most popular</a> Python ML and deep learning library to implement ML workflow and deep learning solution. It is open-source project. It helps to run code on GPU/TPU. PyTorch is also a low-level math library as NumPy, but built for deep learning. It compiles these compute graphs into highly efficient C++/CUDA code.</p> <p>The sources for this content is from product documentation, <a href=https://www.learnpytorch.io/ >Zero to mastery - learning pytorch</a>, and <a href=https://github.com/jeffheaton/app_deep_learning/blob/main/t81_558_class_03_2_pytorch.ipynb>WashU training</a> website.</p> <h2 id=environment-setup>Environment setup<a class=headerlink href=#environment-setup title="Permanent link">&para;</a></h2> <p>Use pip or mini conda for package management and virtual environment management, and jupyter notebooks.</p> <h3 id=install>Install<a class=headerlink href=#install title="Permanent link">&para;</a></h3> <ul> <li> <p>Using Python 3 and pip3, use a virtual environment, install torch</p> <div class=highlight><pre><span></span><code>pip3<span class=w> </span>install<span class=w> </span>torch<span class=w> </span>torchvision<span class=w> </span>torchaudio
</code></pre></div> </li> <li> <p>Using Anaconda:</p> <ol> <li> <p>Install miniconda (it is installed in ~/miniconda3): </p> <div class=highlight><pre><span></span><code><span class=c1># under ~/bin</span>
curl<span class=w> </span>-O<span class=w> </span>https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh
sh<span class=w> </span>Miniconda3-latest-MacOSX-arm64.sh<span class=w> </span>-u
</code></pre></div> </li> <li> <p>Verify installed libraries: <code>conda list</code></p> </li> <li>Environments are created under <code>~/miniconda3/envs</code>. To create a conda environment named "torch", in miniconda3 folder do: <code>conda create anaconda python=3 -n torch</code></li> <li>To activate conda environment: <code>conda activate torch</code></li> <li>Install pytorch <code>conda install pandas pytorch::pytorch torchvision torchaudio -c pytorch</code></li> <li>[optional] Install jupyter packaging: <code>conda install -y jupyter</code></li> <li>Register a new runtime env for jupyter: <code>python -m ipykernel install --user --name pytorch --display-name "Python 3.11 (pytorch)"</code></li> </ol> </li> </ul> <h3 id=run-once-conda-installed>Run once conda installed<a class=headerlink href=#run-once-conda-installed title="Permanent link">&para;</a></h3> <ol> <li>To activate conda environment: <code>conda activate torch</code></li> <li>Test my first program: <code>python basic-torch.py</code> </li> <li>If we need Jupyter: <code>jupyter notebook</code> in the torch env, and then <a href=http://localhost:8888/tree>http://localhost:8888/tree</a>.</li> <li>Select the Kernel to be "Python 3.9 (pytorch)"</li> </ol> <p>My code studies are in <a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch>pytorch</a> folder.</p> <h2 id=concepts>Concepts<a class=headerlink href=#concepts title="Permanent link">&para;</a></h2> <h3 id=tensor>Tensor<a class=headerlink href=#tensor title="Permanent link">&para;</a></h3> <p>Tensor is an important concept for deep learning. It is the numerical representation of data, a n dimension matrix.</p> <p>Tensors are a specialized data structure, similar to NumPy’s <code>ndarrays</code>, except that tensors can run on GPUs. </p> <div class=highlight><pre><span></span><code><span class=n>matrix1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>]],</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</code></pre></div> <p>Tensor attributes describe their shape, datatype, and the device on which they are stored.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span><span class=o>,</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=n>shape</span> <span class=o>=</span> <span class=p>(</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>,)</span>
<span class=n>rand_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=n>shape</span><span class=p>)</span>
<span class=n>ones_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>shape</span><span class=p>)</span>
</code></pre></div> <p>Tensor created from NumPy array:</p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=n>X</span><span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>X</span><span class=p>)</span><span class=o>.</span><span class=n>type</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float</span><span class=p>)</span>
<span class=n>y</span><span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>y</span><span class=p>)</span><span class=o>.</span><span class=n>type</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float</span><span class=p>)</span>
<span class=n>X</span><span class=p>[:</span><span class=mi>5</span><span class=p>],</span><span class=n>y</span><span class=p>[:</span><span class=mi>5</span><span class=p>]</span>
</code></pre></div> <p>Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other. <a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch/get_started/torch-tensor-basic.ipynb>See the set of basic operations on tensor</a>.</p> <p>See the basic ML workflow using Pytorch to work on data and do a linear regression <a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch/get_started/workflow-basic.ipynb>workflow-basic.ipynb</a>.</p> <h3 id=constructs>Constructs<a class=headerlink href=#constructs title="Permanent link">&para;</a></h3> <p>PyTorch has two important modules we can use to create neural network: <code>torch.nn, torch.optim</code>, and two primitives to work with data: <code>torch.utils.data.DataLoader</code> and <code>torch.utils.data.Dataset</code>. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset. See <a href=https://pytorch.org/text/stable/datasets.html>dataset examples</a></p> <ul> <li>See basic code in <a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch/basic-torch.py>basic-torch.py</a> with inline explanations.</li> </ul> <table> <thead> <tr> <th style="text-align: left;">Modules</th> <th style="text-align: left;">Description</th> </tr> </thead> <tbody> <tr> <td style="text-align: left;"><code>torch.nn</code></td> <td style="text-align: left;">Contains all of the building blocks for computational graphs.</td> </tr> <tr> <td style="text-align: left;"><code>torch.nn. Parameter</code></td> <td style="text-align: left;">Stores tensors that can be used with nn.Module. If requires_grad=True gradients descent are calculated automatically.</td> </tr> <tr> <td style="text-align: left;"><code>torch.nn.Module</code></td> <td style="text-align: left;">The base class for all neural network modules. Need to subclass it. Requires a forward() method be implemented.</td> </tr> <tr> <td style="text-align: left;"><code>torch.optim</code></td> <td style="text-align: left;">various optimization algorithms to tell the model parameters how to best change to improve gradient descent and in turn reduce the loss</td> </tr> </tbody> </table> <h3 id=gpu>GPU<a class=headerlink href=#gpu title="Permanent link">&para;</a></h3> <p>On Linux or Windows with nvidia GPU, we need to use the Cuda (Compute Unified Device Architecture) library. See <a href=https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/what-is-dlc.html>AWS deep learning container</a>. For Mac, use <code>mps</code>.</p> <p>Here is sample code to set <code>mps</code> to access GPU (on Mac) for tensor computation:</p> <div class=highlight><pre><span></span><code><span class=n>has_mps</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>mps</span><span class=o>.</span><span class=n>is_built</span><span class=p>()</span>
<span class=n>device</span> <span class=o>=</span> <span class=s2>&quot;mps&quot;</span> <span class=k>if</span> <span class=n>has_mps</span> <span class=k>else</span> <span class=s2>&quot;cuda&quot;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&quot;cpu&quot;</span>
</code></pre></div> <p>NumPy uses only CPU, so we can move to tensor and then tensor.to(device) to move the tensor to GPU, do computation and move back to NumPy</p> <div class=highlight><pre><span></span><code><span class=n>tensor</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>])</span>
<span class=n>tensor_on_gpu</span> <span class=o>=</span> <span class=n>tensor</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
<span class=n>tensor_back_on_cpu</span> <span class=o>=</span> <span class=n>tensor_on_gpu</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</code></pre></div> <p>See <a href=https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/ >Tim Dettmers's guide</a>.</p> <h3 id=basic-algebra-with-pytorch>Basic Algebra with Pytorch<a class=headerlink href=#basic-algebra-with-pytorch title="Permanent link">&para;</a></h3> <p>See <a href=https://github.com/jbcodeforce/ML-studies/blob/master/pytorch/get_started/AlgebraPyTorch.py>Algebra using Pytorch python code.</a></p> <h3 id=loss-functions><a href=https://pytorch.org/docs/stable/nn.html#loss-functions>Loss functions</a><a class=headerlink href=#loss-functions title="Permanent link">&para;</a></h3> <p><a href=https://pytorch.org/docs/stable/nn.html#loss-functions>Cost / loss functions</a> selection depends on the problem to solve. </p> <table> <thead> <tr> <th>Loss function/Optimizer</th> <th>Problem type</th> <th>PyTorch module</th> </tr> </thead> <tbody> <tr> <td><strong>Stochastic Gradient Descent</strong> (SGD) optimizer</td> <td>Classification, regression, many others.</td> <td>torch.optim.SGD()</td> </tr> <tr> <td><strong>Adam Optimizer</strong></td> <td>Classification, regression, many others.</td> <td>torch.optim.Adam()</td> </tr> <tr> <td><strong>Binary cross entropy loss</strong></td> <td>Binary classification</td> <td>torch.nn. BCELossWithLogits or torch.nn.BCELoss</td> </tr> <tr> <td><strong>Cross entropy loss</strong></td> <td>Multi-class classification</td> <td>torch.nn.CrossEntropyLoss</td> </tr> <tr> <td><strong>Mean absolute error</strong> (MAE) or L1 Loss</td> <td>Regression</td> <td>torch.nn.L1Loss</td> </tr> <tr> <td><strong>Mean squared error</strong> (MSE) or L2 Loss</td> <td>Regression</td> <td>torch.nn.MSELoss</td> </tr> </tbody> </table> <p>The <a href=https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a>binary cross-entropy / log loss</a> is used to compute how good are the predicted probabilities. The function uses a negative log probability for a label to be one of the expected class: {0,1}, so when a class is not 1 the loss function result is big.</p> <h3 id=neural-network>Neural network<a class=headerlink href=#neural-network title="Permanent link">&para;</a></h3> <p>A <a href=https://pytorch.org/docs/stable/generated/torch.nn.Module.html>PyTorch neural network</a> declaration is a class that extends <code>nn.Module</code>. The constructor includes the neural network structure, and the class must implement the <code>forward(x)</code> function to pass the input to the network and get the output. The back propagation is done using SGD. This is the most flexible way <a href=https://github.com/jbcodeforce/ML-studies/blob/4271cbd2fa3094cf672e038ee7559997e9d90443/pytorch/classification/nn-classifier.py#L17>to declare a NN</a>. As an alternate the following code uses the Sequential method using the non linear (nn.ReLu()) function between layers.</p> <div class=highlight><pre><span></span><code><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=mi>50</span><span class=p>),</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>50</span><span class=p>,</span> <span class=mi>25</span><span class=p>),</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>25</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</code></pre></div> <p>Neural network has an input layer with # of parameters equal to the number of input features, and the number of output equal to the number of expected responses (1 output for binary classification). The first layer above, is a linear transformation to the incoming data (x): </p> <p><img alt="\Large corr(x,y)" src="https://latex.codecogs.com/svg.latex?y=xA^T+b"> </p> <p>50 is the number of parameters to the first hidden layer. For activation function between hidden layers, ReLU (max(0,x)) is often used when we want non-linearity. The output layer will not use a transfer function for a regression neural network, or use the logistic function for binary classification (just two classes) or log SoftMax for two or more classes.</p> <p>The hyper-parameters to tune are:</p> <ul> <li> <p><strong>The number of neuron in hidden layer</strong>: In general, more hidden neurons means more capability to fit complex problems. But too many, will lead to over fitting. Too few, may lead to under fitting the problem and will sacrifice accuracy.</p> </li> <li> <p><strong>The number of layers</strong>: more layers allow the neural network to perform more of its feature engineering and data preprocessing.</p> </li> <li>The <strong>activation function</strong> between hidden layers and for the output layer.</li> <li>The <strong>loss and optimizer</strong> functions.</li> <li>The <strong>learning rate</strong> of the optimization functions</li> <li>Number of <strong>epochs</strong> to train the model. An epoch as one complete pass over the training set.</li> </ul> <p>For multi class training, <code>LogSoftmax</code> is used as transfer function and <code>CrossEntropyLoss</code> as loss function. With Softmax, the outputs are normalized probabilities that sum up to one.</p> <p>Some code samples:</p> <ul> <li>Basic NN in dual class <a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch/classification/classifications.ipynb>classifier notebook</a> to identify plots on 2 circles.</li> <li><a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch/classification/multiclass-classifier.ipynb>Multi-class classifier notebook</a></li> <li>Python code for a PyTorch neural network for a binary classification on (Sklearn moons dataset) using Loss : <a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch/classification/nn-classifier.py>nn-classifier.py</a>.</li> <li>Computer vision and the CNN <a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch/computer-vision/computer_vision.ipynb>A notebook</a> and <a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch/computer-vision/fashion_cnn.py>Python code</a></li> </ul> <div class=highlight><pre><span></span><code><span class=go>{&#39;model_name&#39;: &#39;FashionMNISTModel&#39;, &#39;model_loss&#39;: 0.41334256529808044, &#39;model_acc&#39;: tensor(0.8498, device=&#39;mps:0&#39;)}</span>
<span class=go>{&#39;model_name&#39;: &#39;FashionNISTCNN&#39;, &#39;model_loss&#39;: 0.3709910213947296, &#39;model_acc&#39;: tensor(0.8716, device=&#39;mps:0&#39;)}</span>
</code></pre></div> <h2 id=model-training>Model training<a class=headerlink href=#model-training title="Permanent link">&para;</a></h2> <h3 id=pytorch-training-loop>PyTorch training loop<a class=headerlink href=#pytorch-training-loop title="Permanent link">&para;</a></h3> <p>For the training loop, the steps to build:</p> <table> <thead> <tr> <th style="text-align: left;">Step</th> <th>What does it do?</th> <th>Code example</th> </tr> </thead> <tbody> <tr> <td style="text-align: left;"><strong>Forward pass</strong></td> <td>The model goes through all of the training data once, performing its forward() function calculations.</td> <td>model(x_train)</td> </tr> <tr> <td style="text-align: left;"><strong>Calculate the loss</strong></td> <td>The model's predictions are compared to the ground truth and evaluated to see how wrong they are.</td> <td>loss = loss_fn(y_pred, y_train)</td> </tr> <tr> <td style="text-align: left;"><strong>Zero gradients</strong></td> <td>The optimizers gradients are set to zero to be recalculated for the specific training step.</td> <td>optimizer.zero_grad()</td> </tr> <tr> <td style="text-align: left;"><strong>Perform back propagation</strong> on the loss</td> <td>Computes the gradient of the loss with respect for every model parameter to be updated (each parameter with requires_grad=True)</td> <td>loss.backward()</td> </tr> <tr> <td style="text-align: left;"><strong>Update the optimizer (gradient descent)</strong></td> <td>Update the parameters with requires_grad=True with respect to the loss gradients in order to improve them.</td> <td>optimizer.step()</td> </tr> </tbody> </table> <p>Example of code for training on multiple epochs:</p> <div class=highlight><pre><span></span><code><span class=n>loss_fn</span><span class=o>=</span><span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
<span class=n>optimizer</span><span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>params</span><span class=o>=</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>

<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>epochs</span><span class=p>):</span>
    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
    <span class=c1># 1. Forward pass</span>
    <span class=n>y_logits</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span><span class=o>.</span><span class=n>squeeze</span><span class=p>()</span>
    <span class=c1># from logits -&gt; prediction probabilities -&gt; prediction labels</span>
    <span class=n>y_pred</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>y_logits</span><span class=p>,</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>loss</span> <span class=o>=</span> <span class=n>loss_fn</span><span class=p>(</span><span class=n>y_logits</span><span class=p>,</span><span class=n>y_train</span><span class=p>)</span>
    <span class=n>acc</span> <span class=o>=</span> <span class=n>accuracy_fn</span><span class=p>(</span><span class=n>y_true</span><span class=o>=</span><span class=n>y_train</span><span class=p>,</span> <span class=n>y_pred</span><span class=o>=</span><span class=n>y_pred</span><span class=p>)</span>

    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</code></pre></div> <p>The rules for performing inference with PyTorch models:</p> <div class=highlight><pre><span></span><code><span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>

<span class=c1># 2. Use the inference mode context manager to make predictions</span>
<span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>inference_mode</span><span class=p>():</span>
    <span class=n>y_preds</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</code></pre></div> <p>See <a href=https://github.com/jbcodeforce/ML-studies/blob/e895a9af9d1d36fe3e5a540d8d0fb3224f71646d/pytorch/computer-vision/engine.py#L5>train_step function in engine.py</a></p> <h3 id=pytorch-testing-loop>PyTorch testing loop<a class=headerlink href=#pytorch-testing-loop title="Permanent link">&para;</a></h3> <p>The typical steps include:</p> <table> <thead> <tr> <th>Step</th> <th>Description</th> <th>Code example</th> </tr> </thead> <tbody> <tr> <td><strong>Forward pass</strong></td> <td>The model goes through all of the test data</td> <td>model(x_test)</td> </tr> <tr> <td><strong>Calculate the loss</strong></td> <td>The model's predictions are compared to the ground truth.</td> <td>loss = loss_fn(y_pred, y_test)</td> </tr> <tr> <td><strong>Calculate evaluation metrics</strong></td> <td>Calculate other evaluation metrics such as accuracy on the test set.</td> <td>Custom function</td> </tr> </tbody> </table> <div class=highlight><pre><span></span><code><span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
<span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>inference_mode</span><span class=p>():</span>
    <span class=c1># 1. Forward pass</span>
    <span class=n>test_logits</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span><span class=o>.</span><span class=n>squeeze</span><span class=p>()</span> 
    <span class=n>test_pred</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>test_logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=c1># 2. Caculate loss/accuracy</span>
    <span class=n>test_loss</span> <span class=o>=</span> <span class=n>loss_fn</span><span class=p>(</span><span class=n>test_logits</span><span class=p>,</span><span class=n>y_test</span><span class=p>)</span>
    <span class=n>test_acc</span> <span class=o>=</span> <span class=n>accuracy_fn</span><span class=p>(</span><span class=n>y_true</span><span class=o>=</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=o>=</span><span class=n>test_pred</span><span class=p>)</span>
</code></pre></div> <p>See <a href=https://github.com/jbcodeforce/ML-studies/blob/e895a9af9d1d36fe3e5a540d8d0fb3224f71646d/pytorch/computer-vision/engine.py#L46>test_step function in engine.py</a></p> <h3 id=improving-a-model>Improving a model<a class=headerlink href=#improving-a-model title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Model improvement technique</th> <th>What does it do?</th> </tr> </thead> <tbody> <tr> <td><strong>Add more layers</strong></td> <td>Each layer potentially increases the learning capabilities of the model with each layer being able to learn some kind of new pattern in the data, more layers is often referred to as making the neural network deeper.</td> </tr> <tr> <td><strong>Add more hidden units</strong></td> <td>Similar to the above, more hidden units per layer means a potential increase in learning capabilities of the model, more hidden units is often referred to as making the neural network wider.</td> </tr> <tr> <td><strong>Fitting for longer (more epochs)</strong></td> <td>The model might learn more if it had more opportunities to look at the data.</td> </tr> <tr> <td><strong>Changing the activation functions</strong></td> <td>Some data just can't be fit with only straight lines, using non-linear activation functions can help.</td> </tr> <tr> <td><strong>Change the learning rate</strong></td> <td>Less model specific, the learning rate of the optimizer decides how much a model should change its parameters each step, too much and the model over corrects, too little and it doesn't learn enough.</td> </tr> <tr> <td><strong>Change the loss function</strong></td> <td>Different problems require different loss functions.</td> </tr> <tr> <td><strong>Use transfer learning</strong></td> <td>Take a pre-trained model from a problem domain similar to ours and adjust it to our own problem.</td> </tr> </tbody> </table> <h3 id=evaluate-classification-models>Evaluate classification models<a class=headerlink href=#evaluate-classification-models title="Permanent link">&para;</a></h3> <p>Classification model can be measured using the at least the following metrics (see more <a href=https://lightning.ai/docs/torchmetrics/stable/ >PyTorch metrics</a>):</p> <table> <thead> <tr> <th style="text-align: left;">Metric name/ Evaluation method</th> <th style="text-align: left;">Definition</th> <th style="text-align: left;">Code</th> </tr> </thead> <tbody> <tr> <td style="text-align: left;"><strong>Accuracy</strong></td> <td style="text-align: left;">Out of 100 predictions, how many does your model get correct? E.g. 95% accuracy means it gets 95/100 predictions correct.</td> <td style="text-align: left;">torchmetrics.Accuracy() or sklearn.metrics.accuracy_score()</td> </tr> <tr> <td style="text-align: left;"><strong>Precision</strong></td> <td style="text-align: left;">Proportion of true positives over total number of samples. Higher precision leads to less false positives (model predicts 1 when it should've been 0).</td> <td style="text-align: left;">torchmetrics.Precision() or sklearn.metrics.precision_score()</td> </tr> <tr> <td style="text-align: left;"><strong>Recall</strong></td> <td style="text-align: left;">Proportion of true positives over total number of true positives and false negatives (model predicts 0 when it should've been 1). Higher recall leads to less false negatives.</td> <td style="text-align: left;">torchmetrics.Recall() or sklearn.metrics.recall_score()</td> </tr> <tr> <td style="text-align: left;"><strong>F1-score</strong></td> <td style="text-align: left;">Combines precision and recall into one metric. 1 is best, 0 is worst.</td> <td style="text-align: left;">torchmetrics.F1Score() or sklearn.metrics.f1_score()</td> </tr> <tr> <td style="text-align: left;"><strong>Confusion matrix</strong></td> <td style="text-align: left;">Compares the predicted values with the true values in a tabular way, if 100% correct, all values in the matrix will be top left to bottom right.</td> <td style="text-align: left;"><a href>torchmetrics.classification.ConfusionMatrix</a>https://lightning.ai/docs/torchmetrics/stable/classification/confusion_matrix.html or sklearn.metrics.plot_confusion_matrix()</td> </tr> <tr> <td style="text-align: left;"><strong>Classification report</strong></td> <td style="text-align: left;">Collection of some of the main classification metrics such as precision, recall and f1-score.</td> <td style="text-align: left;"><a href=https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html>sklearn.metrics.classification_report()</a></td> </tr> </tbody> </table> <h2 id=pytorch-datasets>Pytorch datasets<a class=headerlink href=#pytorch-datasets title="Permanent link">&para;</a></h2> <p>PyTorch includes many existing functions to load in various custom datasets in the <a href=https://pytorch.org/vision/stable/index.html>TorchVision</a>, <a href=https://pytorch.org/text/stable/index.html>TorchText</a>, <a href=https://pytorch.org/audio/stable/index.html>TorchAudio</a> and <a href=https://pytorch.org/torchrec/ >TorchRec</a> domain libraries.</p> <p>See <a href=https://github.com/jbcodeforce/ML-studies/blob/master/pytorch/computer-vision/prepare_image_dataset.py>prepare_image_dataset.py</a> to get food images from <a href=https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/ >PyTorch vision</a>.</p> <h3 id=data-augmentation>Data augmentation<a class=headerlink href=#data-augmentation title="Permanent link">&para;</a></h3> <p>Data augmentation is the process of altering the data in such a way that this artificially increases the diversity of the training set.</p> <p>The purpose of <a href=https://pytorch.org/vision/stable/transforms.html>torchvision.transforms</a> is to alter the images in some way and turning them into a tensor, or cropping an image or randomly erasing a portion or randomly rotating them.</p> <p>Training a model on this artificially altered dataset hopefully results in a model that is capable of better <strong>generalization</strong> (the patterns it learns are more robust to future unseen examples).</p> <p>Researches show that random transforms (like <code>transforms.RandAugment()</code> and <code>transforms.TrivialAugmentWide()</code>) generally perform better than hand-picked transforms.</p> <p>We usually don't perform data augmentation on the test set. The idea of data augmentation is to artificially increase the diversity of the training set to better predict on the testing set.</p> <p>See also in <a href=https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_illustrations.html>PyTorch's Illustration of Transforms</a> examples.</p> <h3 id=transfer-learning-for-image-classification>Transfer learning for image classification<a class=headerlink href=#transfer-learning-for-image-classification title="Permanent link">&para;</a></h3> <p>With transfer learning is to take an already well-performing model on a problem-space similar to the one to address and then to customize it.</p> <p>For custom data to go into the model, need to be prepared in the same way as the original training data that went into the model.</p> <p>PyTorch models has weights and we can get the transformers from the weight.</p> <div class=highlight><pre><span></span><code><span class=n>weights</span> <span class=o>=</span> <span class=n>torchvision</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>EfficientNet_B0_Weights</span><span class=o>.</span><span class=n>DEFAULT</span>
<span class=n>transformer</span><span class=o>=</span> <span class=n>weights</span><span class=o>.</span><span class=n>transforms</span><span class=p>()</span>
<span class=n>model</span><span class=o>=</span><span class=n>torchvision</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>efficientnet_b0</span><span class=p>(</span><span class=n>weights</span><span class=o>=</span><span class=n>weights</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</code></pre></div> <p>efficientnet_b0 comes in three main parts:</p> <ul> <li><strong>Features</strong>: A collection of convolutional layers and other various activation layers to learn a base representation of vision data.</li> <li><strong>avgpool</strong>: Takes the average of the output of the features layer(s) and turns it into a feature vector.</li> <li><strong>classifier</strong>: - Turns the feature vector into a vector with the same dimensionality as the number of required output classes (ImageNet has 1000 classes, out_features=1000).</li> </ul> <p>The process of transfer learning usually freezes some base layers of a pre-trained model, typically the features section, and then adjusts the output layers (also called head/classifier layers) to suit our needs.</p> <h2 id=some-how-to>Some How to<a class=headerlink href=#some-how-to title="Permanent link">&para;</a></h2> <details class="- question"> <summary>How to set the device dynamically</summary> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>getDevice</span><span class=p>():</span>
    <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>mps</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
        <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&quot;mps&quot;</span><span class=p>)</span>
    <span class=k>elif</span> <span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
        <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&quot;cuda&quot;</span><span class=p>)</span>
    <span class=k>else</span><span class=p>:</span> 
        <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&quot;cpu&quot;</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>device</span>   
</code></pre></div> </details> <details class="- question"> <summary>How to save and load a model?</summary> <div class=highlight><pre><span></span><code><span class=c1># saving using Pytorch</span>
<span class=n>MODEL_SAVE_PATH</span> <span class=o>=</span> <span class=n>MODEL_PATH</span> <span class=o>/</span> <span class=n>filename</span>
<span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span> <span class=n>MODEL_SAVE_PATH</span><span class=p>)</span>
<span class=c1># Load is reusing the class declaration</span>
<span class=n>model</span><span class=o>=</span><span class=n>FashionNISTCNN</span><span class=p>(</span><span class=n>input_shape</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>hidden_units</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span><span class=n>output_shape</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;models/fashion_cnn_model.pth&quot;</span><span class=p>))</span>
</code></pre></div> </details> <details class="- question"> <summary>Display the confusion matrix for a multiclass prediction</summary> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>make_confusion_matrix</span><span class=p>(</span><span class=n>pred_tensor</span><span class=p>,</span> <span class=n>test_labels</span><span class=p>,</span> <span class=n>class_names</span><span class=p>):</span>
    <span class=c1># Present a confustion matrix between the predicted labels and the true labels from test data</span>
    <span class=n>cm</span> <span class=o>=</span> <span class=n>MulticlassConfusionMatrix</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>class_names</span><span class=p>))</span>
    <span class=n>cm</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>pred_tensor</span><span class=p>,</span> <span class=n>test_labels</span><span class=p>)</span>
    <span class=n>fig</span><span class=p>,</span><span class=n>ax</span> <span class=o>=</span> <span class=n>cm</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>labels</span><span class=o>=</span><span class=n>class_names</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> </details> <details class="- question"> <summary>Transform an image into a Tensor</summary> <p>Use <a href=https://pytorch.org/vision/stable/transforms.html>torchvision.transforms</a> module <div class=highlight><pre><span></span><code><span class=n>train_transformer</span><span class=o>=</span><span class=n>v2</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span><span class=n>v2</span><span class=o>.</span><span class=n>Resize</span><span class=p>((</span><span class=mi>224</span><span class=p>,</span><span class=mi>224</span><span class=p>)),</span> <span class=n>v2</span><span class=o>.</span><span class=n>TrivialAugmentWide</span><span class=p>(</span><span class=n>num_magnitude_bins</span><span class=o>=</span><span class=mi>31</span><span class=p>),</span> <span class=n>v2</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>()])</span>
</code></pre></div></p> </details> <details class="- question"> <summary>How to get visibility into a neural network</summary> <div class=highlight><pre><span></span><code>import torchinfo
torchinfo.summary()
</code></pre></div> </details> <h2 id=code-samples>Code samples<a class=headerlink href=#code-samples title="Permanent link">&para;</a></h2> <ul> <li><a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch/get_started/torch-tensor-basic.ipynb>Basic operations on tensor: my own notebook</a> and <a href=https://www.learnpytorch.io/00_pytorch_fundamentals/#introduction-to-tensors>Learn Pytorch introduction</a>.</li> <li><a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch/get_started/workflow-basic.ipynb>Pytorch workflow for training and testing model</a></li> <li><a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch/computer-vision/fashion_cnn.py>Compute image classification on Fashion NIST images in pythons</a> and <a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch/computer-vision/use_fashion_cnn.py>use_fashion_cnn.pn</a></li> <li><a href=https://github.com/jbcodeforce/ML-studies/tree/master/pytorch/computer-vision/classify_food.py>Pizza, steak, sushi image classifier</a></li> </ul> <h2 id=resources>Resources<a class=headerlink href=#resources title="Permanent link">&para;</a></h2> <ul> <li><a href=https://pytorch.org/tutorials/beginner/basics/intro.html>PyTorch.org tutorial</a></li> <li><a href=https://github.com/mrdbourke/pytorch-deep-learning>Udemy content repo</a></li> <li><a href=https://www.learnpytorch.io/ >Zero to mastery - learning pytorch</a></li> <li><a href=https://github.com/ritchieng/the-incredible-pytorch>The incredible pytorch</a>: curated list of tutorials, projects, libraries, videos, papers, books..</li> <li><a href="https://www.youtube.com/watch?v=f5liqUk0ZTw">Dan Fleisch's video: What's a tensor?</a></li> <li><a href=https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives>How to train state of the art models using Torchvision - PyTorch blog.</a></li> <li><a href=https://github.com/jeffheaton/app_deep_learning/blob/main/t81_558_class_05_2_cnn.ipynb>Jeff Heaton - Using Convolutional Neural Networks.</a></li> </ul> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../pandas/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Pandas"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Pandas </div> </div> </a> <a href=../sklearn/ class="md-footer__link md-footer__link--next" aria-label="Next: Scikit-learn"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Scikit-learn </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2018 - 2024 Jerome Boyer </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/jbcodeforce target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://linkedin.com/in/jeromeboyer target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> <a href target=_blank rel=noopener title class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M536.4-26.3c9.8-3.5 20.6-1 28 6.3s9.8 18.2 6.3 28l-178 496.9c-5 13.9-18.1 23.1-32.8 23.1-14.2 0-27-8.6-32.3-21.7l-64.2-158c-4.5-11-2.5-23.6 5.2-32.6l94.5-112.4c5.1-6.1 4.7-15-.9-20.6s-14.6-6-20.6-.9l-112.4 94.3c-9.1 7.6-21.6 9.6-32.6 5.2L38.1 216.8c-13.1-5.3-21.7-18.1-21.7-32.3 0-14.7 9.2-27.8 23.1-32.8z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "content.code.copy", "content.tooltips", "content.code.copy", "search.highlight", "navigation.instant", "navigation.instant.progress", "navigation.tabs", "navigation.tabs.sticky", "navigation.instant", "navigation.tracking", "navigation.top", "navigation.footer"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.92b07e13.min.js></script> </body> </html>