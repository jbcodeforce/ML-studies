<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=https://jeromeboyer.net/ML-studies/ml/deep-learning/ rel=canonical><link href=../../neuro-symbolic/ rel=prev><link href=../nlp/ rel=next><link rel=icon href=../../assets/logo.drawio.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>Introduction - Machine Learning Studies - Jerome Boyer</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#deep-learning class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Machine Learning Studies - Jerome Boyer" class="md-header__button md-logo" aria-label="Machine Learning Studies - Jerome Boyer" data-md-component=logo> <img src=../../assets/logo.drawio.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Machine Learning Studies - Jerome Boyer </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Introduction </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/jbcodeforce/ML-studies title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> About </a> </li> <li class=md-tabs__item> <a href=../ class=md-tabs__link> Machine Learning </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=./ class=md-tabs__link> Deep Learning </a> </li> <li class=md-tabs__item> <a href=../../genAI/ class=md-tabs__link> Generative AI </a> </li> <li class=md-tabs__item> <a href=../../techno/airflow/ class=md-tabs__link> Techno </a> </li> <li class=md-tabs__item> <a href=../../coding/ class=md-tabs__link> Coding </a> </li> <li class=md-tabs__item> <a href=../../solutions/ class=md-tabs__link> Solutions </a> </li> <li class=md-tabs__item> <a href=https://jbcodeforce.github.io class=md-tabs__link> Home </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Machine Learning Studies - Jerome Boyer" class="md-nav__button md-logo" aria-label="Machine Learning Studies - Jerome Boyer" data-md-component=logo> <img src=../../assets/logo.drawio.png alt=logo> </a> Machine Learning Studies - Jerome Boyer </label> <div class=md-nav__source> <a href=https://github.com/jbcodeforce/ML-studies title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <label class=md-nav__link for=__nav_1 id=__nav_1_label tabindex=0> <span class=md-ellipsis> About </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> About </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../guide_for_ai/ class=md-nav__link> <span class=md-ellipsis> Guide for AI/ML </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_3> <label class=md-nav__link for=__nav_1_3 id=__nav_1_3_label tabindex=0> <span class=md-ellipsis> Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_3_label aria-expanded=false> <label class=md-nav__title for=__nav_1_3> <span class="md-nav__icon md-icon"></span> Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../concepts/ class=md-nav__link> <span class=md-ellipsis> Core concepts </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/maths/ class=md-nav__link> <span class=md-ellipsis> Math summary </span> </a> </li> <li class=md-nav__item> <a href=../../concepts/skill/ class=md-nav__link> <span class=md-ellipsis> Data scientist skill </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_4> <label class=md-nav__link for=__nav_1_4 id=__nav_1_4_label tabindex=0> <span class=md-ellipsis> Architecture </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_1_4> <span class="md-nav__icon md-icon"></span> Architecture </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../architecture/sol-design/ class=md-nav__link> <span class=md-ellipsis> Solution Design </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_5> <label class=md-nav__link for=__nav_1_5 id=__nav_1_5_label tabindex=0> <span class=md-ellipsis> Data management </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_5_label aria-expanded=false> <label class=md-nav__title for=__nav_1_5> <span class="md-nav__icon md-icon"></span> Data management </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../data/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../data/features/ class=md-nav__link> <span class=md-ellipsis> Feature Engineering </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Machine Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Machine Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../classifier/ class=md-nav__link> <span class=md-ellipsis> Classifier </span> </a> </li> <li class=md-nav__item> <a href=../unsupervised/ class=md-nav__link> <span class=md-ellipsis> Unsupervised Learning </span> </a> </li> <li class=md-nav__item> <a href=../../anomaly/ class=md-nav__link> <span class=md-ellipsis> Anomaly detection </span> </a> </li> <li class=md-nav__item> <a href=../../neuro-symbolic/ class=md-nav__link> <span class=md-ellipsis> Hybrid AI </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> Deep Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Deep Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Introduction </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Introduction </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#neural-network class=md-nav__link> <span class=md-ellipsis> Neural Network </span> </a> </li> <li class=md-nav__item> <a href=#classification-neural-network-architecture class=md-nav__link> <span class=md-ellipsis> Classification neural network architecture </span> </a> </li> <li class=md-nav__item> <a href=#recurrent-neural-networks-rnn class=md-nav__link> <span class=md-ellipsis> Recurrent Neural Networks (RNN) </span> </a> <nav class=md-nav aria-label="Recurrent Neural Networks (RNN)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#long-short-term-memory-lstm class=md-nav__link> <span class=md-ellipsis> Long Short-Term Memory (LSTM) </span> </a> </li> <li class=md-nav__item> <a href=#use-cases class=md-nav__link> <span class=md-ellipsis> Use Cases </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#learning class=md-nav__link> <span class=md-ellipsis> Learning </span> </a> <nav class=md-nav aria-label=Learning> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gpu-vs-cpu class=md-nav__link> <span class=md-ellipsis> GPU vs CPU </span> </a> </li> <li class=md-nav__item> <a href=#regularization-techniques class=md-nav__link> <span class=md-ellipsis> Regularization Techniques </span> </a> </li> <li class=md-nav__item> <a href=#data-augmentation class=md-nav__link> <span class=md-ellipsis> Data Augmentation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#computer-image class=md-nav__link> <span class=md-ellipsis> Computer Image </span> </a> <nav class=md-nav aria-label="Computer Image"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#convolutional-neural-network class=md-nav__link> <span class=md-ellipsis> Convolutional Neural Network </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#transfer-learning class=md-nav__link> <span class=md-ellipsis> Transfer Learning </span> </a> </li> <li class=md-nav__item> <a href=#distributed-training class=md-nav__link> <span class=md-ellipsis> Distributed Training </span> </a> </li> <li class=md-nav__item> <a href=#practical-projects class=md-nav__link> <span class=md-ellipsis> Practical Projects </span> </a> </li> <li class=md-nav__item> <a href=#sources-of-information class=md-nav__link> <span class=md-ellipsis> Sources of information </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../nlp/ class=md-nav__link> <span class=md-ellipsis> NLP </span> </a> </li> <li class=md-nav__item> <a href=../../coding/ddp/ class=md-nav__link> <span class=md-ellipsis> Distributed Data Parallel </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Generative AI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Generative AI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../genAI/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/review/ class=md-nav__link> <span class=md-ellipsis> Skill set </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/prompt-eng/ class=md-nav__link> <span class=md-ellipsis> Prompt Engineering </span> </a> </li> <li class=md-nav__item> <a href=../../architecture/sol-design/ class=md-nav__link> <span class=md-ellipsis> Solution Design </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/rag/ class=md-nav__link> <span class=md-ellipsis> RAG </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/agentic/ class=md-nav__link> <span class=md-ellipsis> Agentic AI </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/anthropic/ class=md-nav__link> <span class=md-ellipsis> Anthropic </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/openai/ class=md-nav__link> <span class=md-ellipsis> OpenAI </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/mcp/ class=md-nav__link> <span class=md-ellipsis> MCP </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/mistral/ class=md-nav__link> <span class=md-ellipsis> Mistral </span> </a> </li> <li class=md-nav__item> <a href=../../genAI/cohere/ class=md-nav__link> <span class=md-ellipsis> Cohere </span> </a> </li> <li class=md-nav__item> <a href=../../techno/watsonx/ class=md-nav__link> <span class=md-ellipsis> WatsonX.ai </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Techno </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Techno </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../techno/airflow/ class=md-nav__link> <span class=md-ellipsis> Airflow </span> </a> </li> <li class=md-nav__item> <a href=../../techno/feature_store/ class=md-nav__link> <span class=md-ellipsis> Feature Store </span> </a> </li> <li class=md-nav__item> <a href=../../kaggle/ class=md-nav__link> <span class=md-ellipsis> Kaggle </span> </a> </li> <li class=md-nav__item> <a href=../../techno/opensearch/ class=md-nav__link> <span class=md-ellipsis> OpenSearch </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/python-code/ class=md-nav__link> <span class=md-ellipsis> Python studies </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/yarfba/ai-ml/sagemaker class=md-nav__link> <span class=md-ellipsis> SageMaker </span> </a> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io/spark-studies/ class=md-nav__link> <span class=md-ellipsis> Spark studies </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_8> <label class=md-nav__link for=__nav_5_8 id=__nav_5_8_label tabindex=0> <span class=md-ellipsis> UI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_8_label aria-expanded=false> <label class=md-nav__title for=__nav_5_8> <span class="md-nav__icon md-icon"></span> UI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../techno/gradio/ class=md-nav__link> <span class=md-ellipsis> Gradio </span> </a> </li> <li class=md-nav__item> <a href=../../techno/streamlit/ class=md-nav__link> <span class=md-ellipsis> Streamlit </span> </a> </li> <li class=md-nav__item> <a href=../../techno/taipy/ class=md-nav__link> <span class=md-ellipsis> TaiPy </span> </a> </li> <li class=md-nav__item> <a href=../../techno/nicegui/ class=md-nav__link> <span class=md-ellipsis> NiceGUI </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../techno/gcp/ class=md-nav__link> <span class=md-ellipsis> GCP </span> </a> </li> <li class=md-nav__item> <a href=../../techno/watsonx/ class=md-nav__link> <span class=md-ellipsis> WatsonX.ai </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Coding </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Coding </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../coding/ class=md-nav__link> <span class=md-ellipsis> Coding getting started </span> </a> </li> <li class=md-nav__item> <a href=../../coding/visualization/ class=md-nav__link> <span class=md-ellipsis> Data Visualization </span> </a> </li> <li class=md-nav__item> <a href=../../coding/haystack/ class=md-nav__link> <span class=md-ellipsis> Haystack.ai </span> </a> </li> <li class=md-nav__item> <a href=../../coding/langchain/ class=md-nav__link> <span class=md-ellipsis> LangChain </span> </a> </li> <li class=md-nav__item> <a href=../../coding/langgraph/ class=md-nav__link> <span class=md-ellipsis> LangGraph </span> </a> </li> <li class=md-nav__item> <a href=../../coding/llama-index/ class=md-nav__link> <span class=md-ellipsis> LlamaIndex </span> </a> </li> <li class=md-nav__item> <a href=../../coding/pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../../coding/pytorch/ class=md-nav__link> <span class=md-ellipsis> PyTorch </span> </a> </li> <li class=md-nav__item> <a href=../../coding/sklearn/ class=md-nav__link> <span class=md-ellipsis> Scikit-learn </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7 id=__nav_7_label tabindex=0> <span class=md-ellipsis> Solutions </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Solutions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../solutions/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../techno/players_to_look/ class=md-nav__link> <span class=md-ellipsis> Key AI startups </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=https://jbcodeforce.github.io class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#neural-network class=md-nav__link> <span class=md-ellipsis> Neural Network </span> </a> </li> <li class=md-nav__item> <a href=#classification-neural-network-architecture class=md-nav__link> <span class=md-ellipsis> Classification neural network architecture </span> </a> </li> <li class=md-nav__item> <a href=#recurrent-neural-networks-rnn class=md-nav__link> <span class=md-ellipsis> Recurrent Neural Networks (RNN) </span> </a> <nav class=md-nav aria-label="Recurrent Neural Networks (RNN)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#long-short-term-memory-lstm class=md-nav__link> <span class=md-ellipsis> Long Short-Term Memory (LSTM) </span> </a> </li> <li class=md-nav__item> <a href=#use-cases class=md-nav__link> <span class=md-ellipsis> Use Cases </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#learning class=md-nav__link> <span class=md-ellipsis> Learning </span> </a> <nav class=md-nav aria-label=Learning> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gpu-vs-cpu class=md-nav__link> <span class=md-ellipsis> GPU vs CPU </span> </a> </li> <li class=md-nav__item> <a href=#regularization-techniques class=md-nav__link> <span class=md-ellipsis> Regularization Techniques </span> </a> </li> <li class=md-nav__item> <a href=#data-augmentation class=md-nav__link> <span class=md-ellipsis> Data Augmentation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#computer-image class=md-nav__link> <span class=md-ellipsis> Computer Image </span> </a> <nav class=md-nav aria-label="Computer Image"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#convolutional-neural-network class=md-nav__link> <span class=md-ellipsis> Convolutional Neural Network </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#transfer-learning class=md-nav__link> <span class=md-ellipsis> Transfer Learning </span> </a> </li> <li class=md-nav__item> <a href=#distributed-training class=md-nav__link> <span class=md-ellipsis> Distributed Training </span> </a> </li> <li class=md-nav__item> <a href=#practical-projects class=md-nav__link> <span class=md-ellipsis> Practical Projects </span> </a> </li> <li class=md-nav__item> <a href=#sources-of-information class=md-nav__link> <span class=md-ellipsis> Sources of information </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=deep-learning>Deep learning<a class=headerlink href=#deep-learning title="Permanent link">&para;</a></h1> <div class="admonition - info"> <p class=admonition-title>Update</p> <p>Created 2021 - Updated 1/2026</p> </div> <p>Deep learning is a machine learning techniques which uses neural networks with more than one layer.</p> <h2 id=neural-network>Neural Network<a class=headerlink href=#neural-network title="Permanent link">&para;</a></h2> <p>A Neural Network is a programming approach, based on the biological inspired neuron, used to teach a computer from training data instead of programming it with structured code.</p> <p>The basic structure of a neural network includes an input layer (called "feature vector"), where the data is fed into the model, hidden layers that perform the computational processing, and an output layer that generates the final result. (See YouTube video: <a href="https://www.youtube.com/watch?v=aircAruvnKk">"Neural Network the ground up"</a>).</p> <p>A classical learning example of neural network usage, is to classify images, like the hand written digits of the NIST dataset (<a href=https://github.com/jbcodeforce/ML-studies/blob/master/examples/ml-python/neuralnetwork/shallow_net_demo.ipynb>shallow_net_demo.ipynb</a>). For deeper networks, see <a href=https://github.com/jbcodeforce/ML-studies/blob/master/examples/ml-python/neuralnetwork/Deep_net_keras.ipynb>Deep_net_keras.ipynb</a> and <a href=https://github.com/jbcodeforce/ML-studies/blob/master/examples/ml-python/neuralnetwork/intermediate_nn_keras_demo.ipynb>intermediate_nn_keras_demo.ipynb</a>.</p> <p>A simple neuron holds a function that returns a number between 0 and 1. For example in simple image classification, neuron may hold the grey value of a pixel of a 28x28 pixels image (784 neurons). The number is called <strong>activation</strong>. At the output layer, the number in the neuron represents the percent of one output being the expected response. Neurons are connected together and each connection is weighted.</p> <p>Convolutional neural networks (CNNs) (<a href=https://github.com/jbcodeforce/ML-studies/blob/master/examples/ml-python/neuralnetwork/lenet_in_keras.ipynb>lenet_in_keras.ipynb</a>) allows input size to change without retraining. For the grey digit classification, the CNN defines a neuron as a unique image pattern of 3x3. The output of the regression neural network is numeric, and the classification output is a class.</p> <p>The value of the neuron 'j' in the next layer is computed by the classical logistic equation taking into account previous layer neurons (<code>a</code>) (from 1 to n (i being the index on the number of input)) and the weight of the connection (<code>a(i)</code> to <code>neuron(j)</code>):</p> <p><img alt src="https://latex.codecogs.com/svg.latex?neuron(j)=\sigma (\sum_{i} \omega_{i} * a_{i} - bias)" width=300></p> <p>To get the activation between 0 and 1, it uses the <a href=../../concepts/maths/#sigmoid-function>sigmoid function</a>, the bias is a number to define when the neuron should be active.</p> <p><img alt src=../images/basic-math-neuron-net.png></p> <p>Modern neural network does not use sigmoid function anymore but the <a href=https://en.wikipedia.org/wiki/Rectifier_(neural_networks)>Rectifier Linear unit function</a>.</p> <p><img alt src="https://latex.codecogs.com/svg.image?ReLu(a)=max(0,a)"></p> <p>Neural networks input and output can be an image, a series of numbers that could represent text, audio, or a time series...</p> <p>The simplest architecture is the <a href=../classifier/#perceptron>perceptron</a>, represented by the following diagram:</p> <p><img alt src=../images/perceptron.png></p> <p>There are four types of neurons in a neural network:</p> <ol> <li>Input Neurons - We map each input neuron to one element in the feature vector.</li> <li>Hidden Neurons - Hidden neurons allow the neural network to be abstract and process the input into the output. Each layer receives all the output of previous layer.</li> <li>Output Neurons - Each output neuron calculates one part of the output.</li> <li>Bias Neurons - Work similar to the y-intercept of a linear equation. It introduces a 1 as input.</li> </ol> <p>Neurons is also named nodes, units or summations. See <a href=https://github.com/jbcodeforce/ML-studies/tree/master/examples/deep-neural-net/sigmoid-play.ipynb>the sigmoid play notebook to understand the effect of bias and weights</a> </p> <p>Training refers to the process that determines good weight values.</p> <p>It is possible to use different Activation functions,(or transfer functions), such as hyperbolic tangent, sigmoid/logistic, linear activation function, Rectified Linear Unit (ReLU), Softmax (used for the output of classification neural networks), Linear (used for the output of regression neural networks (or 2-class classification)).</p> <p>ReLU activation function is popular in deep learning because the gradiant descend function needs to take the derivative of the activation function. With sigmoid function, the derivative quickly saturates to zero as it moves from zero, which is not the case for ReLU.</p> <p>The two most used Python frameworks for deep learning are <a href=https://www.tensorflow.org/ >TensorFlow/Keras</a> (Google) or <a href=../../coding/pytorch/ >PyTorch</a> (Facebook).</p> <p>For hands-on introduction to these frameworks, see:</p> <ul> <li><a href=https://github.com/jbcodeforce/ML-studies/blob/master/notebooks/Keras.ipynb>Keras.ipynb</a> - Keras basics with MNIST classification</li> <li><a href=https://github.com/jbcodeforce/ML-studies/blob/master/notebooks/Tensorflow.ipynb>Tensorflow.ipynb</a> - TensorFlow 2.x introduction</li> <li><a href=https://github.com/jbcodeforce/ML-studies/blob/master/examples/pytorch/get_started/torch-tensor-basic.ipynb>torch-tensor-basic.ipynb</a> - PyTorch tensor operations</li> <li><a href=https://github.com/jbcodeforce/ML-studies/blob/master/examples/pytorch/get_started/workflow-basic.ipynb>workflow-basic.ipynb</a> - PyTorch ML workflow</li> </ul> <h2 id=classification-neural-network-architecture>Classification neural network architecture<a class=headerlink href=#classification-neural-network-architecture title="Permanent link">&para;</a></h2> <p>The general architecture of a classification neural network.</p> <table> <thead> <tr> <th>Hyperparameter</th> <th>Classification</th> </tr> </thead> <tbody> <tr> <td>Input layer shape (in_features)</td> <td>Same as number of features</td> </tr> <tr> <td>Hidden layer(s)</td> <td>Problem specific, minimum = 1, maximum = unlimited</td> </tr> <tr> <td>Neurons per hidden layer</td> <td>Problem specific, generally 10 to 512</td> </tr> <tr> <td>Output layer shape (out_features)</td> <td>for binary 1 class, for multi-class: 1 per class</td> </tr> <tr> <td>Hidden layer activation</td> <td>Usually ReLU but can be many others</td> </tr> <tr> <td>Output activation</td> <td>For binary: Sigmoid, for multi-class: Softmax</td> </tr> <tr> <td>Loss function</td> <td>Binary cross entropy. For multi-class Cross entropy</td> </tr> <tr> <td>Optimizer</td> <td>SGD (stochastic gradient descent), Adam (see torch.optim for more options)</td> </tr> </tbody> </table> <p>Below is an example of a very simple NN in PyTorch, without any activation function:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>torch</span><span class=w> </span><span class=kn>import</span> <span class=n>nn</span>

<span class=n>model_0</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>in_features</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>out_features</span><span class=o>=</span><span class=mi>5</span><span class=p>),</span>  <span class=c1># layer 1</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>in_features</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>out_features</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>   <span class=c1># layer 2</span>
<span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

<span class=n>model_0</span>
</code></pre></div> <p>We can use a subclass of pyTorch <code>nn.Module</code> to define the NN. See demonstration in <a href=https://github.com/jbcodeforce/ML-studies/tree/master/examples/pytorch/classification/classifications.ipynb>classifications.ipynb</a> notebook, to search for the circle classes in the sklearn circles dataset, or a multi classes classification in <a href=https://github.com/jbcodeforce/ML-studies/tree/master/examples/pytorch/classification/multiclass-classifier.ipynb>multiclass-classifier.ipynb</a>.</p> <h2 id=recurrent-neural-networks-rnn>Recurrent Neural Networks (RNN)<a class=headerlink href=#recurrent-neural-networks-rnn title="Permanent link">&para;</a></h2> <p>Recurrent Neural Networks are designed to process sequential data where the order of inputs matters. Unlike feedforward networks, RNNs maintain a hidden state that captures information about previous inputs in the sequence.</p> <h3 id=long-short-term-memory-lstm>Long Short-Term Memory (LSTM)<a class=headerlink href=#long-short-term-memory-lstm title="Permanent link">&para;</a></h3> <p>Standard RNNs suffer from the vanishing gradient problem, making it difficult to learn long-range dependencies. LSTM networks address this with a gating mechanism that controls information flow:</p> <ul> <li><strong>Forget gate</strong>: decides what information to discard from the cell state</li> <li><strong>Input gate</strong>: decides which values to update</li> <li><strong>Output gate</strong>: decides what to output based on the cell state</li> </ul> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>tensorflow.keras.layers</span><span class=w> </span><span class=kn>import</span> <span class=n>LSTM</span><span class=p>,</span> <span class=n>Dense</span><span class=p>,</span> <span class=n>Embedding</span>
<span class=kn>from</span><span class=w> </span><span class=nn>tensorflow.keras.models</span><span class=w> </span><span class=kn>import</span> <span class=n>Sequential</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>Sequential</span><span class=p>([</span>
    <span class=n>Embedding</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>,</span> <span class=n>input_length</span><span class=o>=</span><span class=n>max_length</span><span class=p>),</span>
    <span class=n>LSTM</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=n>return_sequences</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
    <span class=n>LSTM</span><span class=p>(</span><span class=mi>64</span><span class=p>),</span>
    <span class=n>Dense</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>)</span>
<span class=p>])</span>
</code></pre></div> <h3 id=use-cases>Use Cases<a class=headerlink href=#use-cases title="Permanent link">&para;</a></h3> <ul> <li><strong>Sentiment analysis</strong>: classifying text as positive/negative based on word sequences</li> <li><strong>Time series prediction</strong>: forecasting stock prices, weather, sensor data</li> <li><strong>Language modeling</strong>: predicting the next word in a sequence</li> <li><strong>Speech recognition</strong>: converting audio sequences to text</li> </ul> <p>See the <a href=https://github.com/jbcodeforce/ML-studies/blob/master/notebooks/Keras-RNN.ipynb>Keras-RNN.ipynb</a> notebook for a sentiment analysis example using LSTM on movie reviews from the IMDB dataset.</p> <h2 id=learning>Learning<a class=headerlink href=#learning title="Permanent link">&para;</a></h2> <p>Same as previous ML problems, we can use supervised ( picture and corresponding classes) and unsupervised learning. For image or voice, the 'self-supervised learning' uses to generate supervisory signals for training data sets by looking at the relationships in the input data.</p> <p>Transfer learning combine a first neural network as input to a second NN. </p> <h3 id=gpu-vs-cpu>GPU vs CPU<a class=headerlink href=#gpu-vs-cpu title="Permanent link">&para;</a></h3> <ol> <li>When the training loss is way lower than the test loss, it means "overfitting" and so loosing time.</li> <li>When both losses are identical, time will be wasted if we try to regularize the model.</li> <li>To optimize deep learning we need to maximize the compute-bound processing by reducing time spent on memory transfer and other things. Bandwidth cost is by moving the data from CPU to GPU, from one node to another, or even from CUDA global memory to CUDA shared memory.</li> </ol> <h3 id=regularization-techniques>Regularization Techniques<a class=headerlink href=#regularization-techniques title="Permanent link">&para;</a></h3> <p>Regularization helps prevent overfitting by adding constraints to the model during training.</p> <p><strong>L1 Regularization (Lasso)</strong>: Adds the absolute value of weights to the loss function. Produces sparse models by driving some weights to zero.</p> <p><img alt src="https://latex.codecogs.com/svg.latex?Loss_{L1}=Loss+\lambda\sum_{i}|w_i|"></p> <p><strong>L2 Regularization (Ridge/Weight Decay)</strong>: Adds the squared magnitude of weights to the loss function. Penalizes large weights without forcing them to zero.</p> <p><img alt src="https://latex.codecogs.com/svg.latex?Loss_{L2}=Loss+\lambda\sum_{i}w_i^2"></p> <p>In PyTorch, L2 regularization is implemented via the <code>weight_decay</code> parameter in optimizers:</p> <div class=highlight><pre><span></span><code><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>,</span> <span class=n>weight_decay</span><span class=o>=</span><span class=mf>1e-4</span><span class=p>)</span>
</code></pre></div> <p><strong>Dropout</strong>: Randomly sets a fraction of input units to zero during training, which prevents neurons from co-adapting. Typical dropout rates are 0.2-0.5.</p> <div class=highlight><pre><span></span><code><span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>  <span class=c1># 50% of neurons dropped</span>
</code></pre></div> <p><strong>Batch Normalization</strong>: Normalizes layer inputs to have zero mean and unit variance. This stabilizes training, allows higher learning rates, and provides slight regularization.</p> <div class=highlight><pre><span></span><code><span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>num_features</span><span class=p>)</span>  <span class=c1># For conv layers</span>
<span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm1d</span><span class=p>(</span><span class=n>num_features</span><span class=p>)</span>  <span class=c1># For linear layers</span>
</code></pre></div> <h3 id=data-augmentation>Data Augmentation<a class=headerlink href=#data-augmentation title="Permanent link">&para;</a></h3> <p>Data augmentation artificially increases training set diversity by applying random transformations to input data. This improves model generalization without collecting more data.</p> <p>For image data, <a href=https://pytorch.org/vision/stable/transforms.html>torchvision.transforms</a> provides common augmentations:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>torchvision</span><span class=w> </span><span class=kn>import</span> <span class=n>transforms</span>

<span class=n>train_transform</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>Resize</span><span class=p>((</span><span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>RandomHorizontalFlip</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>RandomRotation</span><span class=p>(</span><span class=n>degrees</span><span class=o>=</span><span class=mi>15</span><span class=p>),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>ColorJitter</span><span class=p>(</span><span class=n>brightness</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>contrast</span><span class=o>=</span><span class=mf>0.2</span><span class=p>),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=p>[</span><span class=mf>0.485</span><span class=p>,</span> <span class=mf>0.456</span><span class=p>,</span> <span class=mf>0.406</span><span class=p>],</span> <span class=n>std</span><span class=o>=</span><span class=p>[</span><span class=mf>0.229</span><span class=p>,</span> <span class=mf>0.224</span><span class=p>,</span> <span class=mf>0.225</span><span class=p>])</span>
<span class=p>])</span>
</code></pre></div> <p>Research shows that random transforms like <code>TrivialAugmentWide</code> and <code>RandAugment</code> generally outperform hand-picked transforms:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>torchvision.transforms</span><span class=w> </span><span class=kn>import</span> <span class=n>v2</span>
<span class=n>train_transform</span> <span class=o>=</span> <span class=n>v2</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
    <span class=n>v2</span><span class=o>.</span><span class=n>Resize</span><span class=p>((</span><span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)),</span>
    <span class=n>v2</span><span class=o>.</span><span class=n>TrivialAugmentWide</span><span class=p>(</span><span class=n>num_magnitude_bins</span><span class=o>=</span><span class=mi>31</span><span class=p>),</span>
    <span class=n>v2</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>()</span>
<span class=p>])</span>
</code></pre></div> <p>Data augmentation is applied only to training data, not validation or test sets.</p> <h2 id=computer-image>Computer Image<a class=headerlink href=#computer-image title="Permanent link">&para;</a></h2> <p>Address how a computer sees, images.</p> <h3 id=convolutional-neural-network>Convolutional Neural Network<a class=headerlink href=#convolutional-neural-network title="Permanent link">&para;</a></h3> <p>A <a href=https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53>Neural Network</a> to process images by assigning learnable weights and biases to various aspects/objects in the image, and be able to differentiate one from the other. It can successfully capture the spatial and temporal dependencies in an image through the application of relevant filters.</p> <p>Image has three matrices of values matching the size of the picture (H*W) and the RGB value R matrix, G and B matrices. CNN reduces the size of the matrices without loosing the meaning. For that, it uses the concept of Kernel, a window, shifting over the image.</p> <p><img alt src=https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ciDgQEjViWLnCbmX-EeSrA.gif></p> <p>A typical structure of a convolutional neural network:</p> <p><strong>Input layer -&gt; [Convolutional layer -&gt; activation layer -&gt; pooling layer] -&gt; Output layer</strong></p> <p>The layers between [] can be replicated.</p> <p>Every layer in a neural network is trying to compress data from higher dimensional space to lower dimensional space. Below is an example of this method:</p> <div class=highlight><pre><span></span><code><span class=c1># Convolutional layer</span>
<span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=o>=</span><span class=n>input_shape</span><span class=p>,</span> <span class=n>out_channels</span><span class=o>=</span><span class=n>hidden_units</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span>
<span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>  <span class=c1># activation layer</span>
<span class=c1># pooling layer</span>
<span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>    
</code></pre></div> <ul> <li>Conv2d is compressing the information stored in the image to a smaller dimension image</li> <li>MaxPool2d takes the maximum value from a portion of a tensor and disregard the rest.</li> </ul> <p>See this <a href=https://poloclub.github.io/cnn-explainer/ >CNN explainer tool.</a></p> <p>Simple image dataset using the <a href=https://github.com/zalandoresearch/fashion-mnist>Fashion NIST</a>.</p> <p>Code examples for CNN implementations:</p> <ul> <li><a href=https://github.com/jbcodeforce/ML-studies/tree/master/examples/pytorch/computer-vision/fashion_cnn.py>fashion_cnn.py</a> - PyTorch CNN for Fashion MNIST</li> <li><a href=https://github.com/jbcodeforce/ML-studies/tree/master/examples/pytorch/computer-vision/tiny_vgg.py>tiny_vgg.py</a> - TinyVGG architecture implementation</li> <li><a href=https://github.com/jbcodeforce/ML-studies/tree/master/examples/pytorch/computer-vision/computer_vision.ipynb>computer_vision.ipynb</a> - Computer vision notebook walkthrough</li> <li><a href=https://github.com/jbcodeforce/ML-studies/blob/master/notebooks/Keras-CNN.ipynb>Keras-CNN.ipynb</a> - CNN with Keras for MNIST digit classification</li> <li><a href=https://github.com/jbcodeforce/ML-studies/blob/master/examples/ml-python/neuralnetwork/AlexnetJb.ipynb>AlexnetJb.ipynb</a> - AlexNet implementation</li> </ul> <p><a href="https://www.youtube.com/watch?v=iaSUYvmCekI&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=4">MIT - Convolutional Neural Network presentation - video</a></p> <h2 id=transfer-learning>Transfer Learning<a class=headerlink href=#transfer-learning title="Permanent link">&para;</a></h2> <p>Take an existing pre-trained model, and use it on our own data to fine tune the parameters. It helps to get better results with less data, and lesser cost and time. In Computer Vision, <a href=https://www.image-net.org>Image Net</a> includes million of images on which models were trained. </p> <p><a href=https://pytorch.org/vision/stable/models.html>PyTorch has pre-trained models</a>, <a href=https://huggingface.co/models>Hugging Face</a> too, <a href=https://github.com/huggingface/pytorch-image-models>PyTorch Image Models - Timm</a> is a collection of image models, layers, utilities, optimizers, schedulers, data-loaders / augmentations, and reference training / validation scripts that can be reused. <a href=https://paperswithcode.com/sota>Paper with code</a> is a collection of the latest state-of-the-art machine learning papers with code implementations attached to the article.</p> <p>The custom data going into the model needs to be prepared in the same way as the original training data that went into the model: </p> <div class=highlight><pre><span></span><code><span class=c1># load existing NN weights</span>
<span class=n>weights</span> <span class=o>=</span> <span class=n>torchvision</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>EfficientNet_B0_Weights</span><span class=o>.</span><span class=n>DEFAULT</span>
<span class=c1># Get the transforms used to create our pretrained weights</span>
<span class=n>transformer</span><span class=o>=</span> <span class=n>weights</span><span class=o>.</span><span class=n>transforms</span><span class=p>()</span>
</code></pre></div> <p>The transformer is used to create the data loaders:</p> <div class=highlight><pre><span></span><code><span class=n>train_dl</span><span class=p>,</span><span class=n>test_dl</span><span class=p>,</span> <span class=n>classes</span><span class=o>=</span><span class=n>data_setup</span><span class=o>.</span><span class=n>create_data_loaders</span><span class=p>(</span>
                            <span class=n>train_dir</span><span class=p>,</span>
                            <span class=n>test_dir</span><span class=p>,</span>
                            <span class=n>transformer</span><span class=p>,</span>
                            <span class=n>transformer</span><span class=p>,</span>
                            <span class=n>batch_size</span><span class=o>=</span><span class=n>BATCH_SIZE</span><span class=p>)</span>
</code></pre></div> <p>Then, take an existing model. Often bigger models are better but results may also being linked to the type of device used and the hardware resource capacity. <code>efficientnet_b0</code> has 288,548 parameters.</p> <div class=highlight><pre><span></span><code>model=torchvision.models.efficientnet_b0(weights=weights).to(device)
</code></pre></div> <details class="- info"> <summary>efficientnet_b0 parts</summary> <p><code>efficientnet_b0</code> comes in three main parts:</p> <ul> <li><strong>features</strong>: A collection of convolutional layers and other various activation layers to learn a base representation of vision data.</li> <li><strong>avgpool</strong>: Takes the average of the output of the features layer(s) and turns it into a feature vector.</li> <li><strong>classifier</strong>: Turns the feature vector into a vector with the same dimensionality as the number of required output classes (since efficientnet_b0 is pretrained on ImageNet with 1000 classes.</li> </ul> </details> <p>The process of transfer learning usually goes: freeze some base layers of a pre-trained model (typically the features section) and then adjust the output layers (also called head/classifier layers) to suit the needs.</p> <div class=highlight><pre><span></span><code><span class=k>for</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>features</span><span class=o>.</span><span class=n>parameters</span><span class=p>():</span>  <span class=c1># Freeze the features</span>
    <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span> <span class=o>=</span> <span class=kc>False</span>

<span class=n>model</span><span class=o>.</span><span class=n>classifier</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
        <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>inplace</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span> 
        <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>in_features</span><span class=o>=</span><span class=mi>1280</span><span class=p>,</span> 
                        <span class=n>out_features</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>classes</span><span class=p>),</span> 
                        <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>))</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</code></pre></div> <p>Dropout layers randomly remove connections between two neural network layers with a probability of p. This practice is meant to help regularize (prevent overfitting) a model by making sure the connections that remain learn features to compensate for the removal of the other connections.</p> <p>See <a href=https://github.com/jbcodeforce/ML-studies/tree/master/examples/pytorch/computer-vision/transfer_learning.py>PyTorch transfer learning for image classification code.</a></p> <h2 id=distributed-training>Distributed Training<a class=headerlink href=#distributed-training title="Permanent link">&para;</a></h2> <p>Training large models requires distributing computation across multiple GPUs or machines. PyTorch provides Distributed Data Parallel (DDP) for this purpose.</p> <p>DDP replicates the model across GPUs, splits data batches, and synchronizes gradients after each backward pass using the Ring AllReduce algorithm. This allows training to scale efficiently while maintaining model consistency.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>torch.nn.parallel</span><span class=w> </span><span class=kn>import</span> <span class=n>DistributedDataParallel</span> <span class=k>as</span> <span class=n>DDP</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.distributed</span><span class=w> </span><span class=kn>import</span> <span class=n>init_process_group</span>

<span class=c1># Setup process group</span>
<span class=n>init_process_group</span><span class=p>(</span><span class=n>backend</span><span class=o>=</span><span class=s2>&quot;nccl&quot;</span><span class=p>,</span> <span class=n>rank</span><span class=o>=</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=o>=</span><span class=n>world_size</span><span class=p>)</span>

<span class=c1># Wrap model with DDP</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>DDP</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>device_ids</span><span class=o>=</span><span class=p>[</span><span class=n>gpu_id</span><span class=p>])</span>
</code></pre></div> <p>For multi-GPU training with fault tolerance, use <code>torchrun</code>:</p> <div class=highlight><pre><span></span><code>torchrun<span class=w> </span>--standalone<span class=w> </span>--nproc_per_node<span class=o>=</span>gpu<span class=w> </span>multi_gpu_torchrun.py<span class=w> </span><span class=m>50</span><span class=w> </span><span class=m>10</span>
</code></pre></div> <p>See the <a href=../../coding/ddp/ >Distributed Data Parallel documentation</a> for detailed coverage and the following code examples:</p> <ul> <li><a href=https://github.com/jbcodeforce/ML-studies/tree/master/examples/pytorch/ddp/multi_gpu_ddp.py>multi_gpu_ddp.py</a> - Basic DDP implementation</li> <li><a href=https://github.com/jbcodeforce/ML-studies/tree/master/examples/pytorch/ddp/multi_gpu_torchrun.py>multi_gpu_torchrun.py</a> - Training with torchrun</li> <li><a href=https://github.com/jbcodeforce/ML-studies/tree/master/examples/pytorch/ddp/multinode.py>multinode.py</a> - Multi-machine training</li> </ul> <h2 id=practical-projects>Practical Projects<a class=headerlink href=#practical-projects title="Permanent link">&para;</a></h2> <p>For a hands-on project applying deep learning concepts, see <a href=https://github.com/jbcodeforce/ML-studies/blob/master/notebooks/DeepLearningProject-Solution.ipynb>DeepLearningProject-Solution.ipynb</a> which builds a Multi-Layer Perceptron to classify mammogram masses as benign or malignant.</p> <h2 id=sources-of-information>Sources of information<a class=headerlink href=#sources-of-information title="Permanent link">&para;</a></h2> <ul> <li><a href=https://huggingface.co/learn/deep-rl-course/en/unit0/introduction>HuggingFace deep reinforcement </a></li> <li><a href=https://d2l.ai>Dive into Deep Learning</a> - Comprehensive online book from Amazon</li> <li><a href=https://www.learnpytorch.io/ >Learn PyTorch for deep learning</a> - Zero to mastery course</li> <li><a href=https://horace.io/brrr_intro.html>Horace He - Making Deep Learning Go Brrrr From First Principles</a></li> <li><a href="https://www.youtube.com/watch?v=iaSUYvmCekI&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=4">MIT - Convolutional Neural Network presentation - video</a></li> <li><a href=https://github.com/jeffheaton/t81_558_deep_learning>Jeff Heaton - Applications of Deep Neural Networks</a> - WashU course materials</li> <li><a href=https://pytorch.org/docs/stable/index.html>PyTorch documentation</a></li> <li><a href=https://www.tensorflow.org/tutorials>TensorFlow/Keras documentation</a></li> <li><a href=https://paperswithcode.com/ >Papers with Code</a> - State-of-the-art papers with implementations</li> </ul> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../neuro-symbolic/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Hybrid AI"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Hybrid AI </div> </div> </a> <a href=../nlp/ class="md-footer__link md-footer__link--next" aria-label="Next: NLP"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> NLP </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2018 - 2024 Jerome Boyer </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/jbcodeforce target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://linkedin.com/in/jeromeboyer target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> <a href target=_blank rel=noopener title class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M536.4-26.3c9.8-3.5 20.6-1 28 6.3s9.8 18.2 6.3 28l-178 496.9c-5 13.9-18.1 23.1-32.8 23.1-14.2 0-27-8.6-32.3-21.7l-64.2-158c-4.5-11-2.5-23.6 5.2-32.6l94.5-112.4c5.1-6.1 4.7-15-.9-20.6s-14.6-6-20.6-.9l-112.4 94.3c-9.1 7.6-21.6 9.6-32.6 5.2L38.1 216.8c-13.1-5.3-21.7-18.1-21.7-32.3 0-14.7 9.2-27.8 23.1-32.8z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["content.code.annotate", "content.code.copy", "content.tooltips", "content.code.copy", "search.highlight", "navigation.instant", "navigation.instant.progress", "navigation.tabs", "navigation.tabs.sticky", "navigation.instant", "navigation.tracking", "navigation.top", "navigation.footer"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> </body> </html>