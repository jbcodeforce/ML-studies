# LLM with core API like Ollama or OpenAI API

This folder includes different examples using pure lower level APIs without langchain or langgraph.

## Chat with ollama API

The first example is to use terminal to chat with ollama mistral model. The code is chat_with_mistral.py.

## Asynch chat with ollama


## Combine with vector store for RAG
